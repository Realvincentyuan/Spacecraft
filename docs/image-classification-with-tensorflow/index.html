<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Image Classification with TensorFlow</title>
    <link rel="stylesheet" href="../assets/built/screen.css%3Fv=077dc313fa.css">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.12.3/tocbot.css">

    <style>
        .gh-content {
            position: relative;
            z-index: 1;
        }

        /*-- Remove underline in the TOC text  */
        .gh-content a {
            text-decoration: none;
        }

        .gh-content img{
            position: relative;
            z-index: 2;
        }

        .gh-toc > .toc-list {
            position: relative;
            
        }

        .toc-list {
            overflow: hidden;
            list-style: none;
            left: 20%;

        }

        @media (min-width: 1300px) {
            .gh-sidebar {
                position: absolute; 
                top: 0;
                bottom: 0;
                margin-top: 4vmin;
                /* grid-column: wide-start / main-start;  Place the TOC to the left of the content */
                grid-column: main-end / wide-end ; /* Place the TOC to the right of the content */

            }
        
            .gh-toc {
                position: sticky; /* On larger screens, TOC will stay in the same spot on the page */
                top: 4vmin;

                /*-- Send the TOC to the back, in case it is overlapped with images  */
                z-index: 1; 

            }
        }

        /*-- Hide TOC on mobile devices */
        @media (max-width: 768px) {
            .gh-toc {
                display: none;
            }
        }

        .gh-toc .is-active-link::before {
            background-color: var(--ghost-accent-color); /* Defines TOC   accent color based on Accent color set in Ghost Admin */

        } 
    </style>

    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="Spacecraft">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Image Classification with TensorFlow">
    <meta property="og:description" content="1 Introduction

This article discusses the task of multi-class image classification using TensorFlow. The main topics covered include loading image data, data augmentation, model training, transfer learning, and the use of TensorBoard. All the code examples are based on TensorFlow v2.8.0. The code can be run on Google">
    <meta property="og:url" content="https://realvincentyuan.github.io/Spacecraft/image-classification-with-tensorflow/">
    <meta property="og:image" content="https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000">
    <meta property="article:published_time" content="2022-05-28T05:00:00.000Z">
    <meta property="article:modified_time" content="2024-07-07T21:07:36.000Z">
    <meta property="article:tag" content="Tech">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="TensorFlow">
    
    <meta property="article:publisher" content="https://www.facebook.com/ghost">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Image Classification with TensorFlow">
    <meta name="twitter:description" content="1 Introduction

This article discusses the task of multi-class image classification using TensorFlow. The main topics covered include loading image data, data augmentation, model training, transfer learning, and the use of TensorBoard. All the code examples are based on TensorFlow v2.8.0. The code can be run on Google">
    <meta name="twitter:url" content="https://realvincentyuan.github.io/Spacecraft/image-classification-with-tensorflow/">
    <meta name="twitter:image" content="https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Vincent Yuan">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Tech, AI, Python, TensorFlow">
    <meta name="twitter:site" content="@ghost">
    <meta name="twitter:creator" content="@RealVincentYuan">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="800">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Spacecraft",
        "url": "https://realvincentyuan.github.io/Spacecraft/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://realvincentyuan.github.io/Spacecraft/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Vincent Yuan",
        "image": {
            "@type": "ImageObject",
            "url": "https://realvincentyuan.github.io/Spacecraft/content/images/2024/07/avatar-1.png",
            "width": 752,
            "height": 752
        },
        "url": "https://realvincentyuan.github.io/Spacecraft/author/vincent-2/",
        "sameAs": [
            "https://unsplash.com/@vincentyuan87",
            "https://twitter.com/RealVincentYuan"
        ]
    },
    "headline": "Image Classification with TensorFlow",
    "url": "https://realvincentyuan.github.io/Spacecraft/image-classification-with-tensorflow/",
    "datePublished": "2022-05-28T05:00:00.000Z",
    "dateModified": "2024-07-07T21:07:36.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&ixlib=rb-4.0.3&q=80&w=2000",
        "width": 1200,
        "height": 800
    },
    "keywords": "Tech, AI, Python, TensorFlow",
    "description": "1 Introduction\n\nThis article discusses the task of multi-class image classification using TensorFlow. The main topics covered include loading image data, data augmentation, model training, transfer learning, and the use of TensorBoard. All the code examples are based on TensorFlow v2.8.0. The code can be run on Google Colab, which provides free GPU acceleration to speed up the training process.\n\n\n2 Image Processing\n\nLoading the original image data containing 10 classes of objects:\n\nimport zipfil",
    "mainEntityOfPage": "https://realvincentyuan.github.io/Spacecraft/image-classification-with-tensorflow/"
}
    </script>

    <meta name="generator" content="Ghost 5.87">
    <link rel="alternate" type="application/rss+xml" title="Spacecraft" href="../rss/index.html">
    
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/sodo-search.min.js" data-key="59658b4dc0364cacbc3332171d" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/main.css" data-sodo-search="https://realvincentyuan.github.io/Spacecraft/" crossorigin="anonymous"></script>
    
    <link href="https://realvincentyuan.github.io/Spacecraft/webmentions/receive/" rel="webmention">
    <script defer src="../public/cards.min.js%3Fv=077dc313fa"></script><style>:root {--ghost-accent-color: #0f69c2;}</style>
    <link rel="stylesheet" type="text/css" href="../public/cards.min.css%3Fv=077dc313fa.css">
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-633EG809GP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-633EG809GP');
</script>

<!-- Reading progress bar -->
<style>
.reading-progress {
  position: fixed;
  top: 0;
  z-index: 999;
  width: 100%;
  height: 5px; /* Progress bar height */
  background: #c5d2d9; /* Progress bar background color */
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; /* Hide default progress bar */
}

.reading-progress::-webkit-progress-bar {
  background-color: transparent;
}

.reading-progress::-webkit-progress-value {
  background: var(--ghost-accent-color); /* Progress bar color */
}
</style>


<!--   Scroll Top Button  -->
<style>
    /*Scroll to Top CSS*/
    .scroll-top {
		position: fixed;
 		z-index: 50;
		padding: 0;
		right: 30px;
		bottom: 100px;
		opacity: 0;
		visibility: hidden;
		transform: translateY(15px);    
		height: 46px;
		width: 46px;
		cursor: pointer;
		display: flex;
  		align-items: center;
  		justify-content: center;
		border-radius: 50%;
  	transition: all .4s ease;
  	border: none;
  	box-shadow: inset 0 0 0 2px #ccc;
  	color: #ccc;
  	background-color: #fff;
	}

	.scroll-top.is-active {
		opacity: 1;
  		visibility: visible;
  		transform: translateY(0);
	}

	.scroll-top .icon-tabler-arrow-up {
  		position: absolute;
  		stroke-width: 2px;
  		stroke: #333;
	}

	.scroll-top svg path { 
		fill: none; 
	}

	.scroll-top svg.progress-circle path {
		stroke: #333;
		stroke-width: 4;
  		transition: all .4s ease;
	}

	.scroll-top:hover {
  		color: var(--ghost-accent-color);
	}

	.scroll-top:hover .progress-circle path, .scroll-top:hover .icon-tabler-arrow-up {
  		stroke: var(--ghost-accent-color);
	}
          
</style>

    <button class="btn-toggle-round scroll-top js-scroll-top" type="button" title="Scroll to top">
      <svg class="progress-circle" width="100%" height="100%" viewBox="-1 -1 102 102">
        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
      </svg>
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-arrow-up" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="cuurentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <line x1="12" y1="5" x2="12" y2="19" />
        <line x1="18" y1="11" x2="12" y2="5" />
        <line x1="6" y1="11" x2="12" y2="5" />
      </svg>
    </button>



<!-- Code highlights -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
</head>

<body class="post-template tag-tech tag-ai tag-python tag-tensorflow  is-head-middle-logo has-serif-title has-serif-body">
<div class="site">

    <header id="gh-head" class="gh-head gh-outer">
        <div class="gh-head-inner gh-inner">
            <div class="gh-head-brand">
                <div class="gh-head-brand-wrapper">
                    <a class="gh-head-logo" href="../index.html">
                            Spacecraft
                    </a>
                </div>
                <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M17.5 17.5L12.5 12.5L17.5 17.5ZM14.1667 8.33333C14.1667 9.09938 14.0158 9.85792 13.7226 10.5657C13.4295 11.2734 12.9998 11.9164 12.4581 12.4581C11.9164 12.9998 11.2734 13.4295 10.5657 13.7226C9.85792 14.0158 9.09938 14.1667 8.33333 14.1667C7.56729 14.1667 6.80875 14.0158 6.10101 13.7226C5.39328 13.4295 4.75022 12.9998 4.20854 12.4581C3.66687 11.9164 3.23719 11.2734 2.94404 10.5657C2.65088 9.85792 2.5 9.09938 2.5 8.33333C2.5 6.78624 3.11458 5.30251 4.20854 4.20854C5.30251 3.11458 6.78624 2.5 8.33333 2.5C9.88043 2.5 11.3642 3.11458 12.4581 4.20854C13.5521 5.30251 14.1667 6.78624 14.1667 8.33333Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</button>
                <button class="gh-burger"></button>
            </div>

            <nav class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="../index.html">Home</a></li>
    <li class="nav-tech"><a href="../tag/tech/index.html">Tech</a></li>
    <li class="nav-profession"><a href="../tag/pro/index.html">Profession</a></li>
    <li class="nav-life"><a href="../tag/life/index.html">Life</a></li>
    <li class="nav-about"><a href="../about/index.html">About</a></li>
</ul>

            </nav>

            <div class="gh-head-actions">
                        <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M17.5 17.5L12.5 12.5L17.5 17.5ZM14.1667 8.33333C14.1667 9.09938 14.0158 9.85792 13.7226 10.5657C13.4295 11.2734 12.9998 11.9164 12.4581 12.4581C11.9164 12.9998 11.2734 13.4295 10.5657 13.7226C9.85792 14.0158 9.09938 14.1667 8.33333 14.1667C7.56729 14.1667 6.80875 14.0158 6.10101 13.7226C5.39328 13.4295 4.75022 12.9998 4.20854 12.4581C3.66687 11.9164 3.23719 11.2734 2.94404 10.5657C2.65088 9.85792 2.5 9.09938 2.5 8.33333C2.5 6.78624 3.11458 5.30251 4.20854 4.20854C5.30251 3.11458 6.78624 2.5 8.33333 2.5C9.88043 2.5 11.3642 3.11458 12.4581 4.20854C13.5521 5.30251 14.1667 6.78624 14.1667 8.33333Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</button>
            </div>
        </div>
    </header>


    <div class="site-content">
        
<main class="site-main">


    <article class="post tag-tech tag-ai tag-python tag-tensorflow">

        <header class="gh-article-header gh-canvas">

        <div class="article-tag post-card-tags">
        </div>

            <h1 class="gh-article-title">Image Classification with TensorFlow</h1>

            <div class="post-meta">
                <a href="../author/vincent-2/index.html">Vincent Yuan</a>&nbsp;·&nbsp;updated on&nbsp;
                <time datetime="2022-05-28">Jul 7, 2024</time>&nbsp;·&nbsp;<span class="gh-card-length">6 min read</span>
            </div>

            <div class="post-meta">
                    <a class="post-tag tag-tech" href="../tag/tech/index.html" title="Tech">Tech</a>
                    <a class="post-tag tag-ai" href="../tag/ai/index.html" title="AI">AI</a>
                    <a class="post-tag tag-python" href="../tag/python/index.html" title="Python">Python</a>
                    <a class="post-tag tag-tensorflow" href="../tag/tensorflow/index.html" title="TensorFlow">TensorFlow</a>
            </div>

                <figure class="gh-article-image">
        <img
            class="post-image"
            srcset="https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;400 400w,
                    https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;750 750w,
                    https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960 960w,
                    https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1140 1140w,
                    https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1920 1920w"
            sizes="(min-width: 1200px) 960px, 92vw"
            src="https://images.unsplash.com/photo-1694140962022-83b981bc2db3?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHZ5YmxvZ3xlbnwwfHx8fDE3MjAzODY0MzF8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960"
            alt="Image Classification with TensorFlow"
        >
            <figcaption><span style="white-space: pre-wrap;">Photo by </span><a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;"> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption>
    </figure>
        </header>

        <div class="gh-content gh-canvas">

            <aside class="gh-sidebar"><div class="gh-toc"></div></aside> 

            <h2 id="1-introduction">1 Introduction</h2><p>This article discusses the task of multi-class image classification using TensorFlow. The main topics covered include loading image data, data augmentation, model training, transfer learning, and the use of TensorBoard. All the code examples are based on TensorFlow v2.8.0. The code can be run on Google Colab, which provides free GPU acceleration to speed up the training process.</p><h2 id="2-image-processing">2 Image Processing</h2><p>Loading the original image data containing 10 classes of objects:</p><pre><code class="language-python">import zipfile
import os
import matplotlib.pyplot as plt
import datetime

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.python.ops.gen_array_ops import shape
from tensorflow.keras import layers

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip

# Unzip the downloaded file
zip_ref = zipfile.ZipFile("10_food_classes_all_data.zip", "r")
zip_ref.extractall()
zip_ref.close()

# Function for processing images
def load_and_process_image(file_name, img_shape=224):
  """
  Read an image and process it, reshape it to (img_shape, img_shape, color_channels)
  """
  # Read the image
  img = tf.io.read_file(file_name)

  # Decode the read file into a tensor
  img = tf.image.decode_image(img)

  # Resize the image
  img = tf.image.resize(img, size=[img_shape, img_shape])

  # Scale the image
  img = img/255.

  return img

# Function to display files
def list_files(startpath):
    for root, dirs, files in os.walk(startpath):
        level = root.replace(startpath, '').count(os.sep)
        indent = ' ' * 4 * (level)
        print('{}{}/'.format(indent, os.path.basename(root)))
        subindent = ' ' * 4 * (level + 1)
        for f in files:
            print('{}{}'.format(subindent, f))

# Walk through the 10_food_classes directory and list the number of files
for dirpath, dirnames, filenames in os.walk("10_food_classes_all_data"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
</code></pre><p>From the output, we can see that the data contains images of various food items such as ice cream, steak, pizza, etc.</p><pre><code class="language-py">There are 2 directories and 0 images in '10_food_classes_all_data'.
There are 10 directories and 0 images in '10_food_classes_all_data/test'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_wings'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/pizza'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/grilled_salmon'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/sushi'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/fried_rice'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/ice_cream'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_curry'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/hamburger'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/ramen'.
There are 0 directories and 250 images in '10_food_classes_all_data/test/steak'.
There are 10 directories and 0 images in '10_food_classes_all_data/train'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_wings'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/pizza'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/grilled_salmon'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/sushi'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/fried_rice'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/ice_cream'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_curry'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/hamburger'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/ramen'.
There are 0 directories and 750 images in '10_food_classes_all_data/train/steak'.</code></pre><p>Extract all the labels:</p><pre><code class="language-py">class_names = os.listdir("10_food_classes_all_data/train/")
train_dir = "10_food_classes_all_data/train/"
test_dir = "10_food_classes_all_data/test/"
</code></pre><p>In addition, use the TensorFlow's <a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?ref=localhost">tensorflow.keras.preprocessing.image.ImageDataGenerator</a> API to process and enhance the images. In short, this API can automatically generate labels for images based on the file directory and enhance the images according to the specified operations. Note that "data augmentation can only be used on the training set."</p><pre><code class="language-py">train_datagen_augmented = ImageDataGenerator(rescale=1/255.,
                                             rotation_range=20, # Rotate images
                                             shear_range=0.2, # Shear images
                                             zoom_range=0.2, # Zoom images
                                             width_shift_range=0.2, # Shift images horizontally
                                             height_shift_range=0.2, # Shift images vertically
                                             horizontal_flip=True) # Flip images horizontally

train_datagen = ImageDataGenerator(rescale=1/255.)

test_datagen = ImageDataGenerator(rescale=1/255.)

# Generate the datasets
train_data = train_datagen_augmented.flow_from_directory(train_dir,
                                                        target_size=(224,224),
                                                        batch_size=32,
                                                        shuffle=True)

test_data = test_datagen.flow_from_directory(test_dir,
                                              target_size=(224,224),
                                              batch_size=32)
</code></pre><h2 id="3-modeling">3 Modeling</h2><h3 id="31-baseline-model">3.1 Baseline Model</h3><p>First, create a convolutional neural network as the baseline model:</p><pre><code class="language-py"># Plot the training curves
def plot_loss_curves(history):
  """
  Returns separate loss curves for training and validation metrics.
  """
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  # Plot loss
  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # Plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend()


# Build the model
tf.random.set_seed(42)
tf.keras.backend.clear_session()

cnn_model = tf.keras.models.Sequential([
    layers.Conv2D(filters=10, kernel_size=(3,3), activation="relu",
                  input_shape=(224, 224, 3)),
    layers.MaxPooling2D(pool_size=2),

    layers.Conv2D(filters=10, kernel_size=(3,3), activation="relu"),
    layers.MaxPooling2D(pool_size=2),

    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(10, activation="softmax")
])

cnn_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
                optimizer=tf.keras.optimizers.Adam(),
                steps_per_execution=50,
                metrics="accuracy")


def create_tensorboard_callback(dir_name, experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
  print(f"Saving tensorboard callback log file to {log_dir}")
  return tensorboard_callback


tf_board_callback =  create_tensorboard_callback

(dir_name="vision_model",
                                                 experiment_name="VGG_base")

history_cnn = cnn_model.fit(train_data,
                            steps_per_epoch=len(train_data),
                            epochs=5,
                            validation_data=test_data,
                            validation_steps=len(test_data),
                            callbacks=[tf_board_callback])

cnn_model.evaluate(test_data)
</code></pre><p>The output shows the accuracy of the model:</p><pre><code class="language-py">79/79 [==============================] - 12s 148ms/step - loss: 1.8068 - accuracy: 0.3852
[1.8068159818649292, 0.38519999384880066]
</code></pre><p>The training curves indicate the trends of the loss and accuracy. If the model is deepened or trained for a longer time, better accuracy can be achieved.</p><pre><code class="language-py">plot_loss_curves(history_cnn)
</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/cnn_loss.png" class="kg-image" alt="" loading="lazy" width="378" height="278"><figcaption><span style="white-space: pre-wrap;">Loss curve</span></figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/cnn_accuracy.png" class="kg-image" alt="" loading="lazy" width="384" height="278"><figcaption><span style="white-space: pre-wrap;">Accuracy curve</span></figcaption></figure><h3 id="32-transfer-learning">3.2 Transfer Learning</h3><p>Another approach to improve model performance is to use transfer learning. Transfer learning involves using a model that has performed very well on other tasks and applying it to your own task. Generally, transfer learning performs better than building a model from scratch because the model architecture and training process have been highly optimized. In this case, we will use the <a href="https://arxiv.org/abs/1610.02357,?ref=localhost">Xception</a> model, which is a highly complex and high-performance model.</p><pre><code class="language-py"># Load the pre-trained Xception model
base_model = tf.keras.applications.xception.Xception(weights='imagenet', include_top=False)
avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
output = tf.keras.layers.Dense(len(class_names), activation='softmax')(avg)
model = tf.keras.Model(inputs=base_model.input, outputs=output)

# Usually, the weights of the pre-trained model are frozen since they have been well-trained and optimized
for layer in base_model.layers:
    layer.trainable = False

optimizer = tf.keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

epochs = 5
tf_board_callback_2 =  create_tensorboard_callback(dir_name="vision_model",
                                                   experiment_name="Xception")

history = model.fit(train_data, epochs=epochs, validation_data=test_data,
                    callbacks=[tf_board_callback_2])

model.evaluate(test_data)
</code></pre><p>The output shows the improved performance compared to the baseline:</p><pre><code class="language-py">79/79 [==============================] - 31s 390ms/step - loss: 0.5771 - accuracy: 0.8388
[0.5770677924156189, 0.8388000130653381]
</code></pre><p>You can view the training process in TensorBoard:</p><pre><code class="language-py"># The following commands are for Google Colab only
%load_ext tensorboard
%tensorboard --logdir="vision_model/Xception/20220522-120512/"
</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/tensorboard.png" class="kg-image" alt="" loading="lazy" width="1960" height="1624"><figcaption><span style="white-space: pre-wrap;">Visualization of the training process in TensorBoard</span></figcaption></figure><p>You can also download the computational graph of the model in TensorBoard. The complexity of Xception is significantly higher than the baseline model, explaining its superior performance.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/xception_train.png" class="kg-image" alt="" loading="lazy" width="2420" height="1721"><figcaption><span style="white-space: pre-wrap;">Model architecture</span></figcaption></figure><h2 id="4-conclusion">4 Conclusion</h2><p>This article covers important concepts in image classification tasks using neural networks and important TensorFlow APIs, such as <code>tensorflow.keras.preprocessing.image.ImageDataGenerator</code>, <code>TensorBoard Callback</code>, and how to load pre-trained models. I hope this sharing has been helpful to you. Feel free to leave comments for further discussion!</p>
        </div>

        <div class="pagination-container gh-canvas">
        <nav class="pagination">

            <div class="pagination-left">
                    <a class="newer-posts" href="../free-experiment-platform-amazon-sagemaker-studio-lab/index.html">
                        <span class="pagination-label">Previous</span>
                        Free Experiment Platform - Amazon SageMaker Studio Lab
                    </a>
            </div>

            <div class="pagination-right">
                    <a class="older-posts" href="../amex-default-prediction-kaggle-competition-summary/index.html">
                        <span class="pagination-label">Next</span>
                        AMEX - Default Prediction Kaggle Competition Summary
                    </a>
            </div>

        </nav>
        </div>


    </article>


</main>
    </div>

    <footer class="gh-foot gh-outer">
        <div class="gh-foot-inner gh-inner">
            <div class="gh-copyright">
                Spacecraft © 2025
            </div>
                <nav class="gh-foot-menu">
                    <ul class="nav">
    <li class="nav-sign-up"><a href="index.html#/portal/">Sign up</a></li>
</ul>

                </nav>
            <div class="gh-powered-by">
                <a href="https://ghost.org/" target="_blank" rel="noopener">Powered by Ghost</a>
            </div>
        </div>
    </footer>

</div>

    <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="pswp__bg"></div>

    <div class="pswp__scroll-wrap">
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
<script
    src="https://code.jquery.com/jquery-3.3.1.min.js"
    integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous">
</script>
<script src="../assets/built/main.min.js%3Fv=077dc313fa"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.12.3/tocbot.min.js"></script>

<script>
    tocbot.init({
        // Where to render the table of contents.
        tocSelector: '.gh-toc',
        // Where to grab the headings to build the table of contents.
        contentSelector: '.gh-content',
        // Which headings to grab inside of the contentSelector element.
        headingSelector: 'h2, h3, h4',
        // Ensure correct positioning
        hasInnerContainers: true,

        orderedList: false,
    });
</script>


<!-- Code highlights -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<!--   Scroll Top Button  -->
<script>
const scrollTopBtn = document.querySelector('.js-scroll-top');
if (scrollTopBtn) {
  scrollTopBtn.onclick = () => {
    window.scrollTo({top: 0, behavior: 'smooth'});
  }
  
  const progressPath = document.querySelector('.scroll-top path');
  const pathLength = progressPath.getTotalLength();
  progressPath.style.transition = progressPath.style.WebkitTransition = 'none';
  progressPath.style.strokeDasharray = `${pathLength} ${pathLength}`;
  progressPath.style.strokeDashoffset = pathLength;
  progressPath.getBoundingClientRect();
  progressPath.style.transition = progressPath.style.WebkitTransition = 'stroke-dashoffset 10ms linear';		
  const updateProgress = function() {
    const scroll = window.scrollY || window.scrollTopBtn || document.documentElement.scrollTopBtn;

    const docHeight = Math.max(
      document.body.scrollHeight, document.documentElement.scrollHeight,
      document.body.offsetHeight, document.documentElement.offsetHeight,
      document.body.clientHeight, document.documentElement.clientHeight
    );

    const windowHeight = Math.max(document.documentElement.clientHeight, window.innerHeight || 0);

    const height = docHeight - windowHeight;
    var progress = pathLength - (scroll * pathLength / height);
    progressPath.style.strokeDashoffset = progress;
  }

  updateProgress();
  const offset = 100;

  window.addEventListener('scroll', function(event) {
    updateProgress();

    //Scroll back to top
    const scrollPos = window.scrollY || window.scrollTopBtn || document.getElementsByTagName('html')[0].scrollTopBtn;
    scrollPos > offset ? scrollTopBtn.classList.add('is-active') : scrollTopBtn.classList.remove('is-active');

  }, false);
}
</script>

</body>
</html>