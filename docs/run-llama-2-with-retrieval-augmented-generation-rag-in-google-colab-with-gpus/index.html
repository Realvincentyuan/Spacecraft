<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs</title>
    <link rel="stylesheet" href="../assets/built/screen.css%3Fv=39200ba622.css">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.12.3/tocbot.css">

    <style>
        .gh-content {
            position: relative;
            z-index: 1;
        }

        /*-- Remove underline in the TOC text  */
        .gh-content a {
            text-decoration: none;
        }

        .gh-content img{
            position: relative;
            z-index: 2;
        }

        .gh-toc > .toc-list {
            position: relative;
            
        }

        .toc-list {
            overflow: hidden;
            list-style: none;
            left: 20%;

        }

        @media (min-width: 1300px) {
            .gh-sidebar {
                position: absolute; 
                top: 0;
                bottom: 0;
                margin-top: 4vmin;
                /* grid-column: wide-start / main-start;  Place the TOC to the left of the content */
                grid-column: main-end / wide-end ; /* Place the TOC to the right of the content */

            }
        
            .gh-toc {
                position: sticky; /* On larger screens, TOC will stay in the same spot on the page */
                top: 4vmin;

                /*-- Send the TOC to the back, in case it is overlapped with images  */
                z-index: 1; 

            }
        }

        /*-- Hide TOC on mobile devices */
        @media (max-width: 768px) {
            .gh-toc {
                display: none;
            }
        }

        .gh-toc .is-active-link::before {
            background-color: var(--ghost-accent-color); /* Defines TOC   accent color based on Accent color set in Ghost Admin */

        } 
    </style>

    <meta name="description" content="Run Llama 2 with RAG in Google Colab.">
    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="Spacecraft">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs">
    <meta property="og:description" content="Run Llama 2 with RAG in Google Colab.">
    <meta property="og:url" content="https://realvincentyuan.github.io/Spacecraft/run-llama-2-with-retrieval-augmented-generation-rag-in-google-colab-with-gpus/">
    <meta property="og:image" content="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000">
    <meta property="article:published_time" content="2024-01-07T21:53:28.000Z">
    <meta property="article:modified_time" content="2024-01-28T04:37:21.000Z">
    <meta property="article:tag" content="Tech">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="GenAI">
    
    <meta property="article:publisher" content="https://www.facebook.com/ghost">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs">
    <meta name="twitter:description" content="Run Llama 2 with RAG in Google Colab.">
    <meta name="twitter:url" content="https://realvincentyuan.github.io/Spacecraft/run-llama-2-with-retrieval-augmented-generation-rag-in-google-colab-with-gpus/">
    <meta name="twitter:image" content="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Vincent Yuan">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Tech, AI, GenAI">
    <meta name="twitter:site" content="@ghost">
    <meta name="twitter:creator" content="@RealVincentYuan">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="800">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Spacecraft",
        "url": "https://realvincentyuan.github.io/Spacecraft/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://realvincentyuan.github.io/Spacecraft/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Vincent Yuan",
        "image": {
            "@type": "ImageObject",
            "url": "https://realvincentyuan.github.io/Spacecraft/content/images/2024/07/avatar-1.png",
            "width": 752,
            "height": 752
        },
        "url": "https://realvincentyuan.github.io/Spacecraft/author/vincent-2/",
        "sameAs": [
            "https://unsplash.com/@vincentyuan87",
            "https://twitter.com/RealVincentYuan"
        ]
    },
    "headline": "Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs",
    "url": "https://realvincentyuan.github.io/Spacecraft/run-llama-2-with-retrieval-augmented-generation-rag-in-google-colab-with-gpus/",
    "datePublished": "2024-01-07T21:53:28.000Z",
    "dateModified": "2024-01-28T04:37:21.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&ixlib=rb-4.0.3&q=80&w=2000",
        "width": 1200,
        "height": 800
    },
    "keywords": "Tech, AI, GenAI",
    "description": "Run Llama 2 with RAG in Google Colab.\n",
    "mainEntityOfPage": "https://realvincentyuan.github.io/Spacecraft/run-llama-2-with-retrieval-augmented-generation-rag-in-google-colab-with-gpus/"
}
    </script>

    <meta name="generator" content="Ghost 5.87">
    <link rel="alternate" type="application/rss+xml" title="Spacecraft" href="../rss/index.html">
    
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/sodo-search.min.js" data-key="59658b4dc0364cacbc3332171d" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/main.css" data-sodo-search="https://realvincentyuan.github.io/Spacecraft/" crossorigin="anonymous"></script>
    
    <link href="https://realvincentyuan.github.io/Spacecraft/webmentions/receive/" rel="webmention">
    <script defer src="../public/cards.min.js%3Fv=39200ba622"></script><style>:root {--ghost-accent-color: #0f69c2;}</style>
    <link rel="stylesheet" type="text/css" href="../public/cards.min.css%3Fv=39200ba622.css">
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-633EG809GP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-633EG809GP');
</script>

<!-- Reading progress bar -->
<style>
.reading-progress {
  position: fixed;
  top: 0;
  z-index: 999;
  width: 100%;
  height: 5px; /* Progress bar height */
  background: #c5d2d9; /* Progress bar background color */
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; /* Hide default progress bar */
}

.reading-progress::-webkit-progress-bar {
  background-color: transparent;
}

.reading-progress::-webkit-progress-value {
  background: var(--ghost-accent-color); /* Progress bar color */
}
</style>


<!--   Scroll Top Button  -->
<style>
    /*Scroll to Top CSS*/
    .scroll-top {
		position: fixed;
 		z-index: 50;
		padding: 0;
		right: 30px;
		bottom: 100px;
		opacity: 0;
		visibility: hidden;
		transform: translateY(15px);    
		height: 46px;
		width: 46px;
		cursor: pointer;
		display: flex;
  		align-items: center;
  		justify-content: center;
		border-radius: 50%;
  	transition: all .4s ease;
  	border: none;
  	box-shadow: inset 0 0 0 2px #ccc;
  	color: #ccc;
  	background-color: #fff;
	}

	.scroll-top.is-active {
		opacity: 1;
  		visibility: visible;
  		transform: translateY(0);
	}

	.scroll-top .icon-tabler-arrow-up {
  		position: absolute;
  		stroke-width: 2px;
  		stroke: #333;
	}

	.scroll-top svg path { 
		fill: none; 
	}

	.scroll-top svg.progress-circle path {
		stroke: #333;
		stroke-width: 4;
  		transition: all .4s ease;
	}

	.scroll-top:hover {
  		color: var(--ghost-accent-color);
	}

	.scroll-top:hover .progress-circle path, .scroll-top:hover .icon-tabler-arrow-up {
  		stroke: var(--ghost-accent-color);
	}
          
</style>

    <button class="btn-toggle-round scroll-top js-scroll-top" type="button" title="Scroll to top">
      <svg class="progress-circle" width="100%" height="100%" viewBox="-1 -1 102 102">
        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
      </svg>
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-arrow-up" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="cuurentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <line x1="12" y1="5" x2="12" y2="19" />
        <line x1="18" y1="11" x2="12" y2="5" />
        <line x1="6" y1="11" x2="12" y2="5" />
      </svg>
    </button>



<!-- Code highlights -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
</head>

<body class="post-template tag-tech tag-ai tag-genai  is-head-middle-logo has-serif-title has-serif-body">
<div class="site">

    <header id="gh-head" class="gh-head gh-outer">
        <div class="gh-head-inner gh-inner">
            <div class="gh-head-brand">
                <div class="gh-head-brand-wrapper">
                    <a class="gh-head-logo" href="../index.html">
                            Spacecraft
                    </a>
                </div>
                <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M17.5 17.5L12.5 12.5L17.5 17.5ZM14.1667 8.33333C14.1667 9.09938 14.0158 9.85792 13.7226 10.5657C13.4295 11.2734 12.9998 11.9164 12.4581 12.4581C11.9164 12.9998 11.2734 13.4295 10.5657 13.7226C9.85792 14.0158 9.09938 14.1667 8.33333 14.1667C7.56729 14.1667 6.80875 14.0158 6.10101 13.7226C5.39328 13.4295 4.75022 12.9998 4.20854 12.4581C3.66687 11.9164 3.23719 11.2734 2.94404 10.5657C2.65088 9.85792 2.5 9.09938 2.5 8.33333C2.5 6.78624 3.11458 5.30251 4.20854 4.20854C5.30251 3.11458 6.78624 2.5 8.33333 2.5C9.88043 2.5 11.3642 3.11458 12.4581 4.20854C13.5521 5.30251 14.1667 6.78624 14.1667 8.33333Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</button>
                <button class="gh-burger"></button>
            </div>

            <nav class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="../index.html">Home</a></li>
    <li class="nav-tech"><a href="../tag/tech/index.html">Tech</a></li>
    <li class="nav-profession"><a href="../tag/pro/index.html">Profession</a></li>
    <li class="nav-life"><a href="../tag/life/index.html">Life</a></li>
    <li class="nav-about"><a href="../about/index.html">About</a></li>
</ul>

            </nav>

            <div class="gh-head-actions">
                        <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M17.5 17.5L12.5 12.5L17.5 17.5ZM14.1667 8.33333C14.1667 9.09938 14.0158 9.85792 13.7226 10.5657C13.4295 11.2734 12.9998 11.9164 12.4581 12.4581C11.9164 12.9998 11.2734 13.4295 10.5657 13.7226C9.85792 14.0158 9.09938 14.1667 8.33333 14.1667C7.56729 14.1667 6.80875 14.0158 6.10101 13.7226C5.39328 13.4295 4.75022 12.9998 4.20854 12.4581C3.66687 11.9164 3.23719 11.2734 2.94404 10.5657C2.65088 9.85792 2.5 9.09938 2.5 8.33333C2.5 6.78624 3.11458 5.30251 4.20854 4.20854C5.30251 3.11458 6.78624 2.5 8.33333 2.5C9.88043 2.5 11.3642 3.11458 12.4581 4.20854C13.5521 5.30251 14.1667 6.78624 14.1667 8.33333Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</button>
            </div>
        </div>
    </header>


    <div class="site-content">
        
<main class="site-main">


    <article class="post tag-tech tag-ai tag-genai featured">

        <header class="gh-article-header gh-canvas">

        <div class="article-tag post-card-tags">
                <span class="post-card-featured"><svg width="16" height="17" viewBox="0 0 16 17" fill="none" xmlns="http://www.w3.org/2000/svg">
    <path d="M4.49365 4.58752C3.53115 6.03752 2.74365 7.70002 2.74365 9.25002C2.74365 10.6424 3.29678 11.9778 4.28134 12.9623C5.26591 13.9469 6.60127 14.5 7.99365 14.5C9.38604 14.5 10.7214 13.9469 11.706 12.9623C12.6905 11.9778 13.2437 10.6424 13.2437 9.25002C13.2437 6.00002 10.9937 3.50002 9.16865 1.68127L6.99365 6.25002L4.49365 4.58752Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
</svg> Featured</span>
        </div>

            <h1 class="gh-article-title">Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs</h1>

            <div class="post-meta">
                <a href="../author/vincent-2/index.html">Vincent Yuan</a>&nbsp;·&nbsp;updated on&nbsp;
                <time datetime="2024-01-07">Jan 27, 2024</time>&nbsp;·&nbsp;<span class="gh-card-length">4 min read</span>
            </div>

            <div class="post-meta">
                    <a class="post-tag tag-tech" href="../tag/tech/index.html" title="Tech">Tech</a>
                    <a class="post-tag tag-ai" href="../tag/ai/index.html" title="AI">AI</a>
                    <a class="post-tag tag-genai" href="../tag/genai/index.html" title="GenAI">GenAI</a>
            </div>

                <figure class="gh-article-image">
        <img
            class="post-image"
            srcset="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;400 400w,
                    https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;750 750w,
                    https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960 960w,
                    https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1140 1140w,
                    https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1920 1920w"
            sizes="(min-width: 1200px) 960px, 92vw"
            src="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960"
            alt="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs"
        >
            <figcaption>Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit">Unsplash</a></figcaption>
    </figure>
        </header>

        <div class="gh-content gh-canvas">

            <aside class="gh-sidebar"><div class="gh-toc"></div></aside> 

            <p>Utilizing GenAI models on Colab with its free GPUs proves advantageous for GenAI developers. It enables faster execution compared to personal computers lacking powerful GPUs, thereby allowing the testing of more ideas within the same timeframe.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/colab_gpu.png" class="kg-image" alt loading="lazy"><figcaption>Colab GPU</figcaption></figure><p>This post will show you how you can:</p><ul><li>Load Llama 2 gguf model from HuggingFace</li><li>Run Llam2 2 with GPUs</li><li>Create a vector store using Pinecone</li><li>Perform question and answering using Retrieval Augmented Generation(RAG)</li></ul><h2 id="1-dependencies">1 Dependencies</h2><p>Firstly, install Python dependencies as below:</p><pre><code class="language-py">!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir

!pip install huggingface_hub   chromadb langchain sentence-transformers pinecone_client</code></pre><p>Then import dependencies as below:</p><pre><code class="language-py">import numpy as np
from huggingface_hub import hf_hub_download
from llama_cpp import Llama

from langchain.llms import LlamaCpp
from langchain.chains import LLMChain
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate</code></pre><p>Then mount the Google Drive to load the <code>NBA player sample data</code> shared by Meta in the <a href="https://github.com/facebookresearch/llama-recipes/blob/main/demo_apps/nba.txt?ref=localhost">llama-recipes repo</a>. This dataset will be used to create the vector store:</p><pre><code class="language-py">from google.colab import drive
drive.mount('/content/drive')

source_text_file = '/content/drive/MyDrive/Research/Data/GenAI/nba.txt'</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/202401071542642.png" class="kg-image" alt loading="lazy"><figcaption>NBA Player Sample Data</figcaption></figure><h2 id="2-load-llama-2-from-huggingface">2 Load Llama 2 from HuggingFace</h2><p>Firstly create a callback manager for the streaming output of text, and specify the model names in the HuggingFace:</p><pre><code class="language-py"># for token-wise streaming so you'll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])

# Download the model
!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf</code></pre><p>Then specify the model path to be loaded into <code>LlamaCpp</code>:</p><pre><code class="language-py">model_path = 'llama-2-7b-chat.Q5_0.gguf'</code></pre><p>Specify the GPU settings:</p><pre><code class="language-py">n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.</code></pre><p>Next, let's load the model using <code>langchain</code> as below:</p><pre><code class="language-py">from langchain.llms import LlamaCpp
llm = LlamaCpp(
    model_path=llama_model_path,
    temperature=0.0,
    top_p=1,
    n_ctx=16000,
    n_gpu_layers=n_gpu_layers,
    n_batch=n_batch,
    callback_manager=callback_manager,
    verbose=True,
)</code></pre><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Be sure to set up <code>n_gpu_layers</code> and <code>n_batch</code>, it shows <code>BLAS = 1</code> in the output if it is set up correctly.</div></div><h2 id="3-rag">3 RAG</h2><p>Retrieval Augmented Generation (RAG) is important because it addresses key limitations of large language models (LLMs). Here's why:</p><ul><li><strong>Factual Accuracy:</strong> LLMs can be creative and articulate, but they aren't always truthful. RAG integrates external knowledge sources, ensuring generated responses are grounded in real facts.</li><li><strong>Reduced Hallucinations:</strong> LLMs can sometimes invent information or make false claims. RAG combats hallucinations by providing LLMs with reliable context from external sources.</li><li><strong>Domain Expertise:</strong> LLMs struggle with specialized topics. RAG allows them access to specific knowledge bases, like medical journals or legal documents, enhancing their responses in niche areas.</li><li><strong>Transparency and Trust:</strong> RAG systems can show their work! Users can see the sources used to generate responses, building trust and enabling fact-checking.</li></ul><p>In short, RAG makes LLMs more reliable, accurate, and versatile, opening doors for their use in areas like education, legal advice, and scientific research. It's a crucial step towards trustworthy and grounded AI.</p><h3 id="31-%08initialize-pinecone">3.1 Initialize Pinecone</h3><p>Let's import a few related packages and initialize Pinecone - a vector store provider.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">💡</div><div class="kg-callout-text">Quick start for Pinecone setup: https://docs.pinecone.io/docs/quickstart</div></div><pre><code class="language-py">from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma

from langchain.embeddings import HuggingFaceEmbeddings</code></pre><p>Get your Pinecone API key and env here:</p><pre><code class="language-py">PINECONE_API_KEY = ''
PINECONE_ENV = ''</code></pre><p>And initialize it:</p><pre><code class="language-py">import pinecone
from langchain.vectorstores import Pinecone

# Initialize Pinecone
pinecone.init(
    api_key=PINECONE_API_KEY,  
    environment=PINECONE_ENV  
)

pinecone_index_nm = 'qabot'</code></pre><h3 id="32-create-a-vector-store">3.2 Create a Vector Store</h3><p>Firstly let's load the data from Colab:</p><pre><code class="language-py">embeddings = HuggingFaceEmbeddings()

# Load the document, split it into chunks, embed each chunk and load it into the vector store.
raw_documents = TextLoader(source_text_file).load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)</code></pre><p>Then create the vector store:</p><pre><code class="language-py"># Send embedding vectors to Pinecone with Langchain

vstore = Pinecone.from_documents(documents, embeddings, index_name=pinecone_index_nm)</code></pre><h3 id="33-rag">3.3 RAG</h3><p>We then use <code>RetrievalQA</code> to retrieve the documents from the vector database and give the model more context on Llama 2, thereby increasing its knowledge.</p><pre><code class="language-py"># use another LangChain's chain, RetrievalQA, to associate Llama with the loaded documents stored in the vector db
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm,
    retriever=vstore.as_retriever(search_kwargs={"k": 1})
)</code></pre><p>Then the model is ready for your questions:</p><pre><code class="language-py">question = "Who is the tallest in Atlanta Hawks"
result = qa_chain({"query": question})</code></pre><p>The response is like: </p><pre><code class="language-py">{'query': 'Who is the tallest in Atlanta Hawks',
 'result': ' The tallest player on the Atlanta Hawks roster is Saddiq Bey at 6\'7".'}</code></pre><h2 id="4-conclusion">4 Conclusion</h2><p>Utilizing the open-source Llama 2 model with RAG, you can create a robust chatbot tailored to your domain knowledge. This capability proves highly beneficial for enterprise users, as it circumvents privacy concerns and data leaks, ensuring everything operates in-house in theory.</p><p>However, there's still more to uncover in our quest to construct a secure and responsible GenAI app at the enterprise level. Stay tuned for further updates.</p><h2 id="reference">Reference</h2><p>Langchain - llama.cpp:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://python.langchain.com/docs/integrations/llms/llamacpp?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Llama.cpp | 🦜️🔗 Langchain</div><div class="kg-bookmark-description">llama-cpp-python is a</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://python.langchain.com/img/favicon.ico" alt=""><span class="kg-bookmark-author">🦜️🔗 LangChain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://python.langchain.com/img/parrot-chainlink-icon.png" alt=""></div></a></figure>
        </div>

        <div class="pagination-container gh-canvas">
        <nav class="pagination">

            <div class="pagination-left">
                    <a class="newer-posts" href="../say-hello-to-2024/index.html">
                        <span class="pagination-label">Previous</span>
                        Say Hello to 2024
                    </a>
            </div>

            <div class="pagination-right">
                    <a class="older-posts" href="../build-a-fraud-intelligence-analyst-powered-by-llama-2-in-google-colab-with-gpus/index.html">
                        <span class="pagination-label">Next</span>
                        Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs
                    </a>
            </div>

        </nav>
        </div>


    </article>


</main>
    </div>

    <footer class="gh-foot gh-outer">
        <div class="gh-foot-inner gh-inner">
            <div class="gh-copyright">
                Spacecraft © 2025
            </div>
                <nav class="gh-foot-menu">
                    <ul class="nav">
    <li class="nav-sign-up"><a href="index.html#/portal/">Sign up</a></li>
</ul>

                </nav>
            <div class="gh-powered-by">
                <a href="https://ghost.org/" target="_blank" rel="noopener">Powered by Ghost</a>
            </div>
        </div>
    </footer>

</div>

    <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="pswp__bg"></div>

    <div class="pswp__scroll-wrap">
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
<script
    src="https://code.jquery.com/jquery-3.3.1.min.js"
    integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous">
</script>
<script src="../assets/built/main.min.js%3Fv=39200ba622"></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.12.3/tocbot.min.js"></script>

<script>
    tocbot.init({
        // Where to render the table of contents.
        tocSelector: '.gh-toc',
        // Where to grab the headings to build the table of contents.
        contentSelector: '.gh-content',
        // Which headings to grab inside of the contentSelector element.
        headingSelector: 'h2, h3, h4',
        // Ensure correct positioning
        hasInnerContainers: true,

        orderedList: false,
    });
</script>


<!-- Code highlights -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-core.min.js" integrity="sha512-9khQRAUBYEJDCDVP2yw3LRUQvjJ0Pjx0EShmaQjcHa6AXiOv6qHQu9lCAIR8O+/D8FtaCoJ2c0Tf9Xo7hYH01Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-fTl/qcO1VgvKtOMApX2PdZzkziyr2stM65GYPLGuYMnuMm1z2JLJG6XVU7C/mR+E7xBUqCivykuhlzfqxXBXbg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<!--   Scroll Top Button  -->
<script>
const scrollTopBtn = document.querySelector('.js-scroll-top');
if (scrollTopBtn) {
  scrollTopBtn.onclick = () => {
    window.scrollTo({top: 0, behavior: 'smooth'});
  }
  
  const progressPath = document.querySelector('.scroll-top path');
  const pathLength = progressPath.getTotalLength();
  progressPath.style.transition = progressPath.style.WebkitTransition = 'none';
  progressPath.style.strokeDasharray = `${pathLength} ${pathLength}`;
  progressPath.style.strokeDashoffset = pathLength;
  progressPath.getBoundingClientRect();
  progressPath.style.transition = progressPath.style.WebkitTransition = 'stroke-dashoffset 10ms linear';		
  const updateProgress = function() {
    const scroll = window.scrollY || window.scrollTopBtn || document.documentElement.scrollTopBtn;

    const docHeight = Math.max(
      document.body.scrollHeight, document.documentElement.scrollHeight,
      document.body.offsetHeight, document.documentElement.offsetHeight,
      document.body.clientHeight, document.documentElement.clientHeight
    );

    const windowHeight = Math.max(document.documentElement.clientHeight, window.innerHeight || 0);

    const height = docHeight - windowHeight;
    var progress = pathLength - (scroll * pathLength / height);
    progressPath.style.strokeDashoffset = progress;
  }

  updateProgress();
  const offset = 100;

  window.addEventListener('scroll', function(event) {
    updateProgress();

    //Scroll back to top
    const scrollPos = window.scrollY || window.scrollTopBtn || document.getElementsByTagName('html')[0].scrollTopBtn;
    scrollPos > offset ? scrollTopBtn.classList.add('is-active') : scrollTopBtn.classList.remove('is-active');

  }, false);
}
</script>

</body>
</html>