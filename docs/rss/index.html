<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Spacecraft]]></title><description><![CDATA[Healthy food for thoughts about this beautiful life!]]></description><link>https://realvincentyuan.github.io/Spacecraft/</link><image><url>https://realvincentyuan.github.io/Spacecraft/favicon.png</url><title>Spacecraft</title><link>https://realvincentyuan.github.io/Spacecraft/</link></image><generator>Ghost 5.87</generator><lastBuildDate>Sun, 27 Apr 2025 19:46:49 GMT</lastBuildDate><atom:link href="https://realvincentyuan.github.io/Spacecraft/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Risk Mitigation in the MANIC Payment Scheme: A Component-Level Analysis]]></title><description><![CDATA[Risk Mitigation in the MANIC Payment Scheme.]]></description><link>https://realvincentyuan.github.io/Spacecraft/risk-mitigation-in-the-manic-payment-scheme-a-component-level-analysis/</link><guid isPermaLink="false">680e7a8633cd4f4b294afeb3</guid><category><![CDATA[Pro]]></category><category><![CDATA[Payment]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 27 Apr 2025 19:41:22 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703693220546-498e09d5ec33?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDYzfHx2eTEyMTh8ZW58MHx8fHwxNzQ1NzY4MjU1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://realvincentyuan.github.io/Spacecraft/the-manic-scheme-in-payment-networksrehensive-analysis-of-transaction-ecosystems/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">The MANIC Scheme in Payment Networks: A Comprehensive Analysis of Transaction Ecosystems</div><div class="kg-bookmark-description">A Comprehensive Analysis of Transaction Ecosystems.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://realvincentyuan.github.io/Spacecraft/favicon.ico" alt="Risk Mitigation in the MANIC Payment Scheme: A Component-Level Analysis"><span class="kg-bookmark-author">Spacecraft</span><span class="kg-bookmark-publisher">Vincent Yuan</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1703693220546-498e09d5ec33?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDYzfHx2eTEyMTh8ZW58MHx8fHwxNzQ1NzY4MjU1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Risk Mitigation in the MANIC Payment Scheme: A Component-Level Analysis"></div></a></figure><img src="https://images.unsplash.com/photo-1703693220546-498e09d5ec33?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDYzfHx2eTEyMTh8ZW58MHx8fHwxNzQ1NzY4MjU1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Risk Mitigation in the MANIC Payment Scheme: A Component-Level Analysis"><p>The MANIC framework&#x2019;s interconnected structure introduces risks at every node, from merchant fraud to network vulnerabilities. Below, we dissect risks specific to each participant and outline mitigation strategies informed by industry practices and technological innovations.</p><h3 id="1-merchant-risks">1. <strong>Merchant Risks</strong></h3><p><strong>Primary Threats</strong>:</p><ul><li><strong>Chargebacks</strong>: High dispute rates (e.g., &#x2265;1% of transactions) trigger penalties and account termination.</li><li><strong>Data Breaches</strong>: Weak PCI DSS compliance exposes cardholder data to theft.</li><li><strong>Reputational Risk</strong>: Association with fraudulent or high-risk industries (e.g., CBD, gambling).</li></ul><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">PCI DSS (Payment Card Industry Data Security Standard) compliance refers to a set of security standards designed to protect cardholder data across payment networks. It is a framework of best practices and guidelines established by the PCI Security Standards Council to ensure that all organizations handling credit card and payment data maintain secure systems and processes to protect that data from fraud, breaches, and theft.</div></div><p><strong>Mitigation Strategies</strong>:</p><ul><li><strong>Dynamic Fraud Detection</strong>: Deploy AI-driven tools (e.g., NMI&#x2019;s machine learning models) to flag suspicious transactions using behavioral analytics (typing speed, device fingerprints).</li><li><strong>Tokenization</strong>: Replace sensitive data with tokens to reduce breach impact.</li><li><strong>Rolling Reserves</strong>: Maintain 5&#x2013;10% of transaction volume in reserve accounts to offset chargeback liabilities.</li></ul><h3 id="2-acquiring-bank-risks">2. <strong>Acquiring Bank Risks</strong></h3><p><strong>Primary Threats</strong>:</p><ul><li><strong>Merchant Default</strong>: High-risk merchants (e.g., those in crypto) may suddenly cease operations, leaving unresolved chargebacks.</li><li><strong>Compliance Failures</strong>: Violations of AML/KYC regulations incur fines up to $1M per incident.</li></ul><p><strong>Mitigation Strategies</strong>:</p><ul><li><strong>Enhanced Underwriting</strong>: Use AI underwriting tools to assess merchant credit scores, industry risk tiers, and transaction history.</li><li><strong>Real-Time Monitoring</strong>: Track chargeback ratios and transaction velocity via platforms like Stax, triggering alerts for anomalies (e.g., &gt;50% MoM volume spikes).</li><li><strong>Contractual Safeguards</strong>: Enforce early termination clauses for merchants exceeding agreed chargeback thresholds.</li></ul><h3 id="3-network-risks">3. <strong>Network Risks</strong></h3><p><strong>Primary Threats</strong>:</p><ul><li><strong>Illicit Use</strong>: Money laundering via prepaid cards or anonymized transactions.</li><li><strong>Operational Disruptions</strong>: Downtime in clearing systems (e.g., VisaNet outages) halts global transactions.</li></ul><p><strong>Mitigation Strategies</strong>:</p><ul><li><strong>Link Analysis</strong>: Map transactional relationships to uncover fraud rings (e.g., detecting mule accounts funding terror groups).</li><li><strong>MACH Architecture</strong>: Adopt cloud-native, microservices-based systems (e.g., Visa Direct) for 99.999% uptime and rapid failover.</li><li><strong>Geo-Blocking</strong>: Restrict transactions from high-risk jurisdictions flagged in OFAC lists.</li></ul><h3 id="4-issuing-bank-risks">4. <strong>Issuing Bank Risks</strong></h3><p><strong>Primary Threats</strong>:</p><ul><li><strong>Credit Risk</strong>: Cardholder defaults (e.g., 3.5% delinquency rates in Q1 2025).</li><li><strong>Account Takeovers</strong>: Stolen credentials used for unauthorized purchases.</li></ul><p><strong>Mitigation Strategies</strong>:</p><ul><li><strong>Behavioral Biometrics</strong>: Deploy passive authentication via typing cadence or screen-touch pressure analysis.</li><li><strong>Dynamic Credit Limits</strong>: Adjust spending caps in real-time based on cardholder income signals (e.g., Plaid&#x2019;s cash flow verification).</li><li><strong>3D Secure 2.0</strong>: Mandate biometric authentication for high-value online transactions.</li></ul><h3 id="5-customer-risks">5. <strong>Customer Risks</strong></h3><p><strong>Primary Threats</strong>:</p><ul><li><strong>Identity Theft</strong>: Stolen card details sold on dark web markets (e.g., $40 avg. price per credit card dump).</li><li><strong>Friendly Fraud</strong>: False chargeback claims (&#x201C;item not received&#x201D;) cost merchants $25B annually.</li></ul><p><strong>Mitigation Strategies</strong>:</p><ul><li><strong>EMV&#xAE; 3-D Secure</strong>: Shift liability to issuers via cryptogram-based authentication.</li><li><strong>Transactional Transparency</strong>: Provide real-time SMS updates with delivery tracking links to deter false disputes.</li><li><strong>Education Campaigns</strong>: Teach customers to recognize phishing attempts via issuer-branded tutorials.</li></ul><h2 id="cross-component-risk-synergies">Cross-Component Risk Synergies</h2>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th style="text-align:left">Risk Type</th>
<th style="text-align:left">Collaborative Mitigation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Data Breaches</strong></td>
<td style="text-align:left">End-to-end encryption (E2EE) across MANIC nodes, audited quarterly via PCI DSS-certified tools.</td>
</tr>
<tr>
<td style="text-align:left"><strong>Money Laundering</strong></td>
<td style="text-align:left">Shared blockchain ledgers between issuers and networks for immutable transaction tracing.</td>
</tr>
<tr>
<td style="text-align:left"><strong>Systemic Fraud</strong></td>
<td style="text-align:left">Federated machine learning models pooling anonymized data from acquirers and networks.</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1726137570741-ed4306ce2904?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wxfDF8c2VhcmNofDh8fGNyZWRpdCUyMGNhcmR8ZW58MHx8fHwxNzQ1NzgyODM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" class="kg-image" alt="Risk Mitigation in the MANIC Payment Scheme: A Component-Level Analysis" loading="lazy" width="6000" height="4000" srcset="https://images.unsplash.com/photo-1726137570741-ed4306ce2904?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wxfDF8c2VhcmNofDh8fGNyZWRpdCUyMGNhcmR8ZW58MHx8fHwxNzQ1NzgyODM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1726137570741-ed4306ce2904?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wxfDF8c2VhcmNofDh8fGNyZWRpdCUyMGNhcmR8ZW58MHx8fHwxNzQ1NzgyODM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1726137570741-ed4306ce2904?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wxfDF8c2VhcmNofDh8fGNyZWRpdCUyMGNhcmR8ZW58MHx8fHwxNzQ1NzgyODM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1726137570741-ed4306ce2904?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wxfDF8c2VhcmNofDh8fGNyZWRpdCUyMGNhcmR8ZW58MHx8fHwxNzQ1NzgyODM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by </span><a href="https://unsplash.com/@sumup?ref=localhost"><span style="white-space: pre-wrap;">SumUp</span></a><span style="white-space: pre-wrap;"> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="future-proofing-the-manic-model">Future-Proofing the MANIC Model</h2><ul><li><strong>Quantum-Resistant Cryptography</strong>: Preparing for Y2Q threats with lattice-based algorithms (NIST-standardized by 2026).</li><li><strong>Decentralized Identity</strong>: Letting customers control data via self-sovereign wallets (e.g., Mastercard&#x2019;s ID Service).</li><li><strong>AI Co-Pilots</strong>: Tools like Stripe Radar 2.0 auto-negotiate chargebacks using generative AI for evidence compilation.</li></ul><p>By layering these technical, contractual, and educational safeguards, stakeholders can reduce MANIC-related losses by 40&#x2013;60% while maintaining transaction velocity. However, balancing security with user experience remains pivotal&#x2014;overly stringent measures (e.g., step-up auth for $10 purchases) risk cart abandonment rates exceeding 35%.</p>]]></content:encoded></item><item><title><![CDATA[The MANIC Scheme in Payment Networks: A Comprehensive Analysis of Transaction Ecosystems]]></title><description><![CDATA[A Comprehensive Analysis of Transaction Ecosystems.]]></description><link>https://realvincentyuan.github.io/Spacecraft/the-manic-scheme-in-payment-networksrehensive-analysis-of-transaction-ecosystems/</link><guid isPermaLink="false">680e4f1f33cd4f4b294afe52</guid><category><![CDATA[Pro]]></category><category><![CDATA[Payment]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 27 Apr 2025 18:31:41 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703693220546-498e09d5ec33?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDYzfHx2eTEyMTh8ZW58MHx8fHwxNzQ1NzY4MjU1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703693220546-498e09d5ec33?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDYzfHx2eTEyMTh8ZW58MHx8fHwxNzQ1NzY4MjU1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="The MANIC Scheme in Payment Networks: A Comprehensive Analysis of Transaction Ecosystems"><p>The modern payment ecosystem relies on a complex interplay of stakeholders to facilitate secure and efficient financial transactions. At the core of this system lies the <strong>MANIC scheme</strong>, an acronym representing the five critical entities involved in credit card processing: <strong>Merchant</strong>, <strong>Acquiring Bank</strong>, <strong>Network</strong>, <strong>Issuing Bank</strong>, and <strong>Customer/Cardholder</strong>. This framework ensures seamless coordination across parties, enabling billions of transactions daily. Below, we dissect each component of the MANIC model, analyze their interdependencies, and explore the technical and economic mechanisms underpinning this ecosystem.</p><h2 id="1-the-manic-framework-core-components-and-roles"><strong>1 The MANIC Framework: Core Components and Roles</strong></h2><h3 id="11-merchant-the-transaction-initiator"><strong>1.1 Merchant: The Transaction Initiator</strong></h3><p>Merchants form the entry point of the payment lifecycle. These entities &#x2014; ranging from retail stores to online platforms &#x2014; accept card payments in exchange for goods or services. When a customer initiates a transaction, the merchant&#x2019;s payment infrastructure (e.g., point-of-sale systems, e-commerce gateways) captures card details and forwards them to the acquiring bank.</p><p><strong>Key Responsibilities</strong>:</p><ul><li><strong>Transaction Initiation</strong>: Triggering the authorization process by submitting payment requests.</li><li><strong>Compliance</strong>: Adhering to Payment Card Industry Data Security Standards (PCI DSS) to protect cardholder data.</li><li><strong>Settlement</strong>: Receiving funds post-transaction after fees are deducted by intermediaries.</li></ul><p><strong>Challenges</strong>:</p><ul><li><strong>Fee Structures</strong>: Merchants bear costs such as interchange fees (paid to issuing banks) and assessment fees (paid to networks).</li><li><strong>Fraud Management</strong>: Implementing tools like tokenization and 3D Secure to mitigate risks.</li></ul><h3 id="12-acquiring-bank-the-merchant%E2%80%99s-financial-partner"><strong>1.2 Acquiring Bank: The Merchant&#x2019;s Financial Partner</strong></h3><p>Acquiring banks (or &#x201C;acquirers&#x201D;) act as intermediaries between merchants and the broader payment network. Institutions like Chase or Worldpay provide merchant accounts, enabling businesses to accept card payments. Their role extends beyond transaction routing; they assume liability for chargebacks and ensure regulatory compliance.</p><p><strong>Operational Workflow</strong>:</p><ul><li><strong>Authorization Request</strong>: The acquirer forwards transaction details to the card network.</li><li><strong>Funds Settlement</strong>: After deducting fees, the acquirer deposits the net amount into the merchant&#x2019;s account.</li><li><strong>Dispute Resolution</strong>: Managing chargebacks and reconciling transactional discrepancies.</li></ul><p><strong>Economic Model</strong>:</p><ul><li>Acquirers profit from markup fees added to interchange rates. For example, a $100 transaction with a 1.65% interchange fee and a 0.20% acquirer markup yields $1.85 in revenue.</li></ul><h3 id="13-network-the-interchange-facilitator"><strong>1.3 Network: The Interchange Facilitator</strong></h3><p>Card networks (Visa, Mastercard, etc.) serve as communication highways, connecting acquirers and issuers. They standardize protocols (e.g., ISO 8583 messaging) and enforce security measures while monetizing transaction volume through assessment fees.</p><p><strong>Technical Infrastructure</strong>:</p><ul><li><strong>Authorization Routing</strong>: Networks validate transactions by checking against issuer-defined rules (e.g., available credit, fraud flags).</li><li><strong>Clearing and Settlement</strong>: Batch processing of transactions ensures funds move from issuers to acquirers.</li></ul><p><strong>Innovations</strong>:</p><ul><li><strong>Cloud-Native Architectures</strong>: Modern networks like Visa Direct leverage MACH (Microservices, API-first, Cloud-native, Headless) principles for real-time payments.</li><li><strong>Tokenization</strong>: Replacing sensitive card data with tokens to enhance security in digital transactions.</li></ul><h3 id="14-issuing-bank-the-cardholder%E2%80%99s-financial-institution"><strong>1.4 Issuing Bank: The Cardholder&#x2019;s Financial Institution</strong></h3><p>Issuing banks (e.g., Bank of America) provide credit/debit cards to consumers. They authorize transactions based on available credit, manage fraud detection systems, and settle obligations with acquirers via networks.</p><p><strong>Authorization Process</strong>:</p><ul><li><strong>Risk Assessment</strong>: Algorithms evaluate transaction patterns, location, and purchase amount to flag suspicious activity.</li><li><strong>Funds Reservation</strong>: Temporarily holding the transaction amount until settlement.</li></ul><p><strong>Revenue Streams</strong>:</p><ul><li><strong>Interchange Fees</strong>: Issuers earn ~1.3&#x2013;2.5% of transaction value, compensating for credit risk and rewards programs.</li><li><strong>Interest and Penalties</strong>: Revenue from cardholder balances and late fees.</li></ul><h3 id="15-customer-the-transaction-originator"><strong>1.5 Customer: The Transaction Originator</strong></h3><p>Cardholders initiate payments by presenting their cards at merchant terminals. Their interaction triggers the MANIC chain, culminating in funds transfer and monthly billing cycles.</p><p><strong>Security Considerations</strong>:</p><ul><li><strong>EMV Chips</strong>: Reduce counterfeit fraud through dynamic authentication.</li><li><strong>Biometric Authentication</strong>: Fingerprint/face recognition in mobile wallets (Apple Pay, Google Pay) enhances security.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fHZ5YmxvZ3xlbnwwfHx8fDE3NDU3NzgxMDl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" class="kg-image" alt="The MANIC Scheme in Payment Networks: A Comprehensive Analysis of Transaction Ecosystems" loading="lazy" width="2000" height="1333" srcset="https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fHZ5YmxvZ3xlbnwwfHx8fDE3NDU3NzgxMDl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fHZ5YmxvZ3xlbnwwfHx8fDE3NDU3NzgxMDl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fHZ5YmxvZ3xlbnwwfHx8fDE3NDU3NzgxMDl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fHZ5YmxvZ3xlbnwwfHx8fDE3NDU3NzgxMDl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000 2000w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by </span><a href="https://unsplash.com/@vincentyuan87?ref=localhost"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;"> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="2-transaction-flow-under-the-manic-model"><strong>2 Transaction Flow Under the MANIC Model</strong></h2><h3 id="21-step-1-authorization"><strong>2.1 Step 1: Authorization</strong></h3><ul><li><strong>Customer</strong> swipes a card at a <strong>Merchant</strong>&#x2019;s terminal.</li><li><strong>Acquirer</strong> sends an authorization request via the <strong>Network</strong> to the <strong>Issuer</strong>.</li><li><strong>Issuer</strong> approves/declines based on fraud checks and available credit.</li></ul><h3 id="22-step-2-authentication"><strong>2.2 Step 2: Authentication</strong></h3><ul><li><strong>3D Secure</strong>: For online transactions, cardholders authenticate via one-time passwords or biometrics.</li></ul><h3 id="23-step-3-clearing-and-settlement"><strong>2.3 Step 3: Clearing and Settlement</strong></h3><ul><li><strong>Batch Processing</strong>: At day&#x2019;s end, the <strong>Acquirer</strong> submits batched transactions to the <strong>Network</strong>, which routes them to <strong>Issuers</strong>.</li><li><strong>Net Settlement</strong>: Issuers transfer funds to acquirers via the network, minus interchange fees.</li></ul><p><strong>Simplified MANIC Transaction Flow</strong>:</p><pre><code>Customer &#x2192; Merchant &#x2192; Acquirer &#x2192; Network &#x2192; Issuer &#x2192; (Approval) &#x2192; Network &#x2192; Acquirer &#x2192; Merchant  </code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1556742044-3c52d6e88c62?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEzfHxwb3MlMjBtYWNoaW5lfGVufDB8fHx8MTc0NTc3ODE0OHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" class="kg-image" alt="The MANIC Scheme in Payment Networks: A Comprehensive Analysis of Transaction Ecosystems" loading="lazy" width="2000" height="1335" srcset="https://images.unsplash.com/photo-1556742044-3c52d6e88c62?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEzfHxwb3MlMjBtYWNoaW5lfGVufDB8fHx8MTc0NTc3ODE0OHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1556742044-3c52d6e88c62?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEzfHxwb3MlMjBtYWNoaW5lfGVufDB8fHx8MTc0NTc3ODE0OHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1556742044-3c52d6e88c62?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEzfHxwb3MlMjBtYWNoaW5lfGVufDB8fHx8MTc0NTc3ODE0OHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1556742044-3c52d6e88c62?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEzfHxwb3MlMjBtYWNoaW5lfGVufDB8fHx8MTc0NTc3ODE0OHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000 2000w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by </span><a href="https://unsplash.com/@claybanks?ref=localhost"><span style="white-space: pre-wrap;">Clay Banks</span></a><span style="white-space: pre-wrap;"> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="3-economic-dynamics-and-fee-structures"><strong>3 Economic Dynamics and Fee Structures</strong></h2><p>The MANIC ecosystem thrives on fee-sharing mechanisms:</p><ul><li><strong>Interchange Fees</strong>: Paid by acquirers to issuers, typically 1.5&#x2013;2.5% per transaction.</li><li><strong>Assessment Fees</strong>: Networks charge 0.13&#x2013;0.15% of volume for infrastructure use.</li><li><strong>Acquirer Markup</strong>: Variable fees added to interchange, often 0.20&#x2013;0.50%.</li></ul><p><strong>Example</strong>: A $100 purchase may incur $1.80 in interchange (1.8%), $0.15 in assessment fees, and $0.30 in acquirer markup, totaling $2.25 in processing costs.</p><h2 id="4-challenges-and-future-trends"><strong>4 Challenges and Future Trends</strong></h2><h3 id="41-regulatory-scrutiny"><strong>4.1 Regulatory Scrutiny</strong></h3><ul><li><strong>Payment for Order Flow (PFOF)</strong>: Critics argue such practices create conflicts of interest, prompting EU plans to ban PFOF by 2026.</li><li><strong>Interchange Caps</strong>: Regulations like the Durbin Amendment (US) limit debit card interchange fees, pressuring issuer revenues.</li></ul><h3 id="42-technological-disruption"><strong>4.2 Technological Disruption</strong></h3><ul><li><strong>Decentralized Finance (DeFi)</strong>: Blockchain-based systems challenge traditional networks by enabling peer-to-peer settlements.</li><li><strong>Real-Time Payments</strong>: FedNow (US) and SEPA Instant (EU) bypass card networks, reducing reliance on MANIC intermediaries.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1457694587812-e8bf29a43845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGZpbGVzfGVufDB8fHx8MTc0NTc3ODIxNnww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" class="kg-image" alt="The MANIC Scheme in Payment Networks: A Comprehensive Analysis of Transaction Ecosystems" loading="lazy" width="2000" height="1333" srcset="https://images.unsplash.com/photo-1457694587812-e8bf29a43845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGZpbGVzfGVufDB8fHx8MTc0NTc3ODIxNnww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1457694587812-e8bf29a43845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGZpbGVzfGVufDB8fHx8MTc0NTc3ODIxNnww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1457694587812-e8bf29a43845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGZpbGVzfGVufDB8fHx8MTc0NTc3ODIxNnww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1457694587812-e8bf29a43845?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGZpbGVzfGVufDB8fHx8MTc0NTc3ODIxNnww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000 2000w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by </span><a href="https://unsplash.com/@mvdheuvel?ref=localhost"><span style="white-space: pre-wrap;">Maarten van den Heuvel</span></a><span style="white-space: pre-wrap;"> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="conclusion"><strong>Conclusion</strong></h2><p>The MANIC scheme represents a finely tuned orchestra of financial institutions, networks, and end-users. While the model has enabled global commerce scalability, emerging technologies and regulatory shifts pose existential questions. Banks and networks adopting MACH architectures and AI-driven fraud detection are poised to lead the next evolution of payment ecosystems. However, balancing innovation with interoperability &#x2014; ensuring the MANIC framework adapts without fragmenting &#x2014; remains the industry&#x2019;s paramount challenge.</p>]]></content:encoded></item><item><title><![CDATA[Support Conversational History in RAG Pipelines with Llama 3]]></title><description><![CDATA[Add memory to Llama 3 with RAG.]]></description><link>https://realvincentyuan.github.io/Spacecraft/support-conversational-history-in-rag-pipelines-with-llama-3/</link><guid isPermaLink="false">668afeb5ac15d470add4a53f</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 07 Jul 2024 20:47:28 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1715398940416-43e3ec908fa0?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQxfHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1715398940416-43e3ec908fa0?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQxfHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Support Conversational History in RAG Pipelines with Llama 3"><p>In Retrieval-Augmented Generation (RAG) pipelines, it&apos;s crucial to help chatbots recall previous conversations, as users may ask follow-up questions that rely on earlier context. However, users&apos; prompts might lack sufficient context, assuming previous discussions are still relevant. To tackle this challenge, incorporating chat history into LLMs&apos; question-answering context enables them to retrieve relevant information for new queries.</p><p>This post presents a solution leveraging LangChain, Llama 3-8B, and Ollama, which can efficiently run on an M2 Pro MacBook Pro with 16 GB memory.</p><h2 id="1-dependencies">1 Dependencies</h2><h3 id="11-ollama-and-llama-3-model">1.1 Ollama and Llama 3 Model</h3><p>Firstly, Ollama should be installed on a MacBook. Ollama can utilize the GPUs of the machine, ensuring efficient inference, provided there is sufficient memory. Llama 3-8B performs well on machines with 16 GB of memory.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Ollama can be downloaded here: <a href="https://ollama.com/?ref=localhost" target="_blank">https://ollama.com/</a></div></div><p>Once it is downloaded, can use below command in the terminal to pull the Llama 3-8B model:</p><pre><code class="language-shell">ollama pull llama3</code></pre><h3 id="12-python-dependencies">1.2 Python Dependencies</h3><p>Now, let&apos;s import the required packages to construct a RAG system with chat history, utilizing the LangChain toolkit.</p><pre><code class="language-python"># Models
from langchain.llms import LlamaCpp
from langchain.chat_models import ChatOpenAI

# Setup
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# Vector store
from langchain.document_loaders import  TextLoader
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

# LangChain supports many other chat models. Here, we&apos;re using Ollama
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate

# RAG with Memory 
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory

# Display results
import markdown
from IPython.display import display, Markdown, Latex</code></pre><h2 id="2-create-vector-store">2 Create Vector Store</h2><p>The source data consists of&#xA0;<a href="https://vincentyuan.us/r/18a4e24d?m=df98d831-fc77-4019-8ad0-29db6fe20ba1&amp;ref=localhost">a summary of important events and statistics</a> from the week of May 13th, 2024, as published by Yahoo Finance. This data is not included in the training set of Llama 3. For demonstration purposes, the news is extracted to a text file and utilized in the code to create the Chroma vector store and retriever.</p><pre><code class="language-python">source_data_path = &apos;../data/yahoo.txt&apos;

# for token-wise streaming so you&apos;ll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])

loader = TextLoader(source_data_path)

documents = loader.load()

#splitting the text into
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(documents)

embedding = HuggingFaceEmbeddings()

vectordb = Chroma.from_documents(documents=texts,
                                 embedding=embedding
                                 # persist_directory=persist_directory
                                )
                                
retriever = vectordb.as_retriever(search_kwargs={&quot;k&quot;: 5})</code></pre><h2 id="3-create-the-llm-object">3 Create the LLM Object</h2><p>Make sure the Ollama is on and the LLama 3 model has been downloaded, then below code can be used to define a LLM object in the pipeline:</p><pre><code class="language-python">llm = ChatOllama(model=&quot;llama3&quot;,
                temperature=0.1)</code></pre><h2 id="4-rag-with-memory">4 RAG with Memory</h2><p>In essence, there should be place to store chat history, also the the chat history is added to the prompt &#xA0;in RAG, so that the LLM can access past conversation, also the chat history is update after each round of conversation. Below is a way to use the&#xA0;<code>BaseChatMessageHistory</code>&#xA0;to address this need:</p><pre><code class="language-python">### Contextualize question ###
contextualize_q_system_prompt = &quot;&quot;&quot;Given a chat history and the latest user question \
which might reference context in the chat history, formulate a standalone question \
which can be understood without the chat history. Do NOT answer the question, \
just reformulate it if needed and otherwise return it as is.&quot;&quot;&quot;
contextualize_q_prompt = ChatPromptTemplate.from_messages(
    [
        (&quot;system&quot;, contextualize_q_system_prompt),
        MessagesPlaceholder(&quot;chat_history&quot;),
        (&quot;human&quot;, &quot;{input}&quot;),
    ]
)
history_aware_retriever = create_history_aware_retriever(
    llm, retriever, contextualize_q_prompt
)


### Answer question ###
qa_system_prompt = &quot;&quot;&quot;You are an assistant for question-answering tasks. \
Use the following pieces of retrieved context to answer the question. \
If you don&apos;t know the answer, just say that you don&apos;t know. \
Use three sentences maximum and keep the answer concise.\

{context}&quot;&quot;&quot;
qa_prompt = ChatPromptTemplate.from_messages(
    [
        (&quot;system&quot;, qa_system_prompt),
        MessagesPlaceholder(&quot;chat_history&quot;),
        (&quot;human&quot;, &quot;{input}&quot;),
    ]
)
question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)

rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)</code></pre><p>Then define the RAG chain:</p><pre><code class="language-python">### Statefully manage chat history ###
store = {}

def get_session_history(session_id: str) -&gt; BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    get_session_history,
    input_messages_key=&quot;input&quot;,
    history_messages_key=&quot;chat_history&quot;,
    output_messages_key=&quot;answer&quot;,
)</code></pre><p>Then let&apos;s try if the model understands the Yahoo Finance analysis, the question is&#xA0;<code>What is the wall street expectation of the April Consumer Price Index (CPI)?</code>.</p><pre><code class="language-python">llm_response = conversational_rag_chain.invoke(
    {&quot;input&quot;: &quot;What is the wall street expectation of the April Consumer Price Index (CPI)?&quot;},
    config={
        &quot;configurable&quot;: {&quot;session_id&quot;: &quot;abc123&quot;}
    },  # constructs a key &quot;abc123&quot; in `store`.
)[&quot;answer&quot;]

print(&apos;=&apos;*50)
display(Markdown(llm_response))</code></pre><p>The response is:</p><pre><code class="language-shell">According to the text, Wall Street expects an annual gain of 3.4% for headline CPI, which includes the price of food and energy, a decrease from the 3.5% headline number in March. Additionally, prices are expected to rise 0.4% on a month-over-month basis, in line with March&apos;s rise.</code></pre><p>This is aligned with the source:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/CPI.png" class="kg-image" alt="Support Conversational History in RAG Pipelines with Llama 3" loading="lazy" width="1358" height="708"><figcaption><span style="white-space: pre-wrap;">Yahoo Finance Analysis</span></figcaption></figure><p>Then, a question is asked based on the output of last question to calculate the double of the expected CPI:</p><pre><code class="language-python">llm_response = conversational_rag_chain.invoke(
    {&quot;input&quot;: &quot;What is the double of the expected CPI in the prior answer?&quot;},
    config={
        &quot;configurable&quot;: {&quot;session_id&quot;: &quot;abc123&quot;}
    },  # constructs a key &quot;abc123&quot; in `store`.
)[&quot;answer&quot;]

print(&apos;=&apos;*50)
display(Markdown(llm_response))</code></pre><p>And this is the output:</p><pre><code class="language-shell">The expected annual gain for headline CPI is 3.4%. The double of this value would be:

2 x 3.4% = 6.8%

So, the double of the expected CPI is 6.8%.</code></pre><p>So the model successfully picks up the information that it returns in the past and answer correctly to the new question.</p><h2 id="5-summary">5 Summary</h2><p>This enhanced solution extends the capabilities of a regular RAG by supporting chat history, making it highly beneficial for multiple rounds of conversations. With Ollama, experiments like this can be run on an affordable laptop with embedded GPUs. A special acknowledgment to Meta for their great work in improving Llama 3.</p><p></p>]]></content:encoded></item><item><title><![CDATA[Build a Regulation Assistant Powered by Llama 2 and Streamlit with Google Colab GPUs]]></title><description><![CDATA[End to end chatbot powered by Llama 2.]]></description><link>https://realvincentyuan.github.io/Spacecraft/build-a-regulation-assistant-powered-by-llama-2-and-streamlit-with-google-colab-gpus/</link><guid isPermaLink="false">668afd59ac15d470add4a52f</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 07 Jul 2024 20:42:19 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1715394016216-f0c45a43ca69?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1715394016216-f0c45a43ca69?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Build a Regulation Assistant Powered by Llama 2 and Streamlit with Google Colab GPUs"><p>In our previous discussion, we explored the concept of creating a web chatbot using Llama 2. However, an incredibly practical application of chatbots is their ability to field questions within specific domains of knowledge. For example, a chatbot can be trained on policies, regulations, and laws, effectively functioning as a knowledge assistant that users can collaborate with. This functionality holds significant value for enterprise users, who often have vast repositories of internal documents that can be utilized to train the chatbot. Employees can then leverage the chatbot as a quick reference tool.</p><p>Furthermore, this solution can be entirely constructed using open-source components, eliminating the need to rely on external APIs like OpenAI and alleviating any privacy concerns.</p><p>This post showcases a compliance assistant built with the utilization of the open-source large language model&#xA0;<code>Llama 2</code>, in conjunction with&#xA0;<code>retrieval-augmented generation (RAG)</code>, all presented through a user-friendly web interface powered by&#xA0;<code>Streamlit</code>.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">The code can be replicated on Google Colab, using free T4 GPUs. Kudos to Google.</div></div><h2 id="1-dependencies">1 Dependencies</h2><p>Firstly, install a few dependencies:</p><pre><code class="language-py">!pip install -q streamlit

!npm install localtunnel

# GPU setup of LangChain
!CMAKE_ARGS=&quot;-DLLAMA_CUBLAS=on&quot; FORCE_CMAKE=1 pip install --force-reinstall llama-cpp-python==0.2.28  --no-cache-dir

!pip install huggingface_hub  chromadb langchain sentence-transformers pypdf </code></pre><p>Then download the Llama 2 model to the Colab notebook:</p><pre><code class="language-py">!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf</code></pre><h3 id="11-mount-the-google-drive">1.1 Mount the Google Drive</h3><p>This chatbot needs to retrieve documents from a vector database which is composed of embeddings of regulations PDFs. The PDFs are saved in Google Drive, so let&apos;s mount the Google Drive so the code can access the PDFs:</p><pre><code class="language-py"># Mount the google drive
from google.colab import drive
drive.mount(&apos;/gdrive&apos;)</code></pre><h2 id="2-build-the-web-chatbot">2 Build the Web Chatbot</h2><p>The web chatbot is like this:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/compliance_bot.png" class="kg-image" alt="Build a Regulation Assistant Powered by Llama 2 and Streamlit with Google Colab GPUs" loading="lazy" width="3456" height="1920"><figcaption><span style="white-space: pre-wrap;">A Compliance Assistant&#xA0;</span></figcaption></figure><p>Below is the entire code to build the compliance assistant, the details of each part will be introduced in the follow section:</p><pre><code class="language-py">%%writefile app.py

import streamlit as st
import os

from langchain.llms import LlamaCpp
from langchain.chains import LLMChain
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate

from langchain.llms import LlamaCpp

from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma

from langchain.chains import RetrievalQA




# App title
st.set_page_config(page_title=&quot;&#x1F999;&#x1F4AC; Llama 2 Chatbot&quot;)

llama_model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;

n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.

# for token-wise streaming so you&apos;ll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])



# ====================== RAG ======================

# Encoding the PDFs
pdf_folder_path = &apos;/gdrive/MyDrive/Research/Data/GenAI/PDFs&apos;

loader = PyPDFDirectoryLoader(pdf_folder_path)

documents = loader.load()

#splitting the text into
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(documents)

# Create vector DB, embed and store the texts
# Supplying a persist_directory will store the embeddings on disk
persist_directory = &apos;db&apos;

## here we are using OpenAI embeddings but in future we will swap out to local embeddings
embedding = HuggingFaceEmbeddings()

vectordb = Chroma.from_documents(documents=texts,
                                 embedding=embedding,
                                 persist_directory=persist_directory)

retriever = vectordb.as_retriever(search_kwargs={&quot;k&quot;: 5})

# ====================== App ======================
with st.sidebar:
    st.title(&apos;&#x1F999;&#x1F4AC; Llama 2 Chatbot&apos;)


    st.subheader(&apos;Models and parameters&apos;)
    selected_model = st.sidebar.selectbox(&apos;Choose a Llama2 model&apos;, [&apos;Llama2-7B&apos;, &apos;Llama2-13B&apos;], key=&apos;selected_model&apos;)

    if selected_model == &apos;Llama2-7B&apos;:
        llm_path = llama_model_path
    elif selected_model == &apos;Llama2-13B&apos;:
        llm_path = llama_model_path

    temperature = st.sidebar.slider(&apos;temperature&apos;, min_value=0.01, max_value=5.0, value=0.1, step=0.01)
    top_p = st.sidebar.slider(&apos;top_p&apos;, min_value=0.01, max_value=1.0, value=0.9, step=0.01)
    max_length = st.sidebar.slider(&apos;max_length&apos;, min_value=32, max_value=128, value=120, step=8)
    st.markdown(&apos;&#x1F4D6; Learn how to build this app in this [blog](https://blog.streamlit.io/how-to-build-a-llama-2-chatbot/)!&apos;)


    llm = LlamaCpp(
      model_path=llm_path,
      temperature=temperature,
      top_p=top_p,
      n_ctx=2048,
      n_gpu_layers=n_gpu_layers,
      n_batch=n_batch,
      callback_manager=callback_manager,
      verbose=True,
    )

    # use another LangChain&apos;s chain, RetrievalQA, to associate Llama with the loaded documents stored in the vector db



# Store LLM generated responses
if &quot;messages&quot; not in st.session_state.keys():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]

# Display or clear chat messages
for message in st.session_state.messages:
    with st.chat_message(message[&quot;role&quot;]):
        st.write(message[&quot;content&quot;])

def clear_chat_history():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]
st.sidebar.button(&apos;Clear Chat History&apos;, on_click=clear_chat_history)


# Function for generating LLaMA2 response. Refactored from https://github.com/a16z-infra/llama2-chatbot
def generate_llama2_response(prompt_input):

    pre_prompt = &quot;&quot;&quot;[INST] &lt;&lt;SYS&gt;&gt;
                  You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.

                  If you cannot answer the question from the given documents, please state that you do not have an answer.\n
                  &quot;&quot;&quot;


    for dict_message in st.session_state.messages:
        if dict_message[&quot;role&quot;] == &quot;user&quot;:
            pre_prompt += &quot;User: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;
        else:
            pre_prompt += &quot;Assistant: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;

    prompt = pre_prompt +  &quot;{context}User : {question}&quot; + &quot;[\INST]&quot;
    llama_prompt = PromptTemplate(template=prompt, input_variables=[&quot;context&quot;,&quot;question&quot;])


    qa_chain = RetrievalQA.from_chain_type(
        llm,
        retriever=retriever,
         chain_type_kwargs={&quot;prompt&quot;: llama_prompt}
    )

    result = qa_chain.run({
                            &quot;query&quot;: prompt_input})


    return result

# User-provided prompt
if prompt := st.chat_input():
    st.session_state.messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt})
    with st.chat_message(&quot;user&quot;):
        st.write(prompt)

# Generate a new response if last message is not from assistant
if st.session_state.messages[-1][&quot;role&quot;] != &quot;assistant&quot;:
    with st.chat_message(&quot;assistant&quot;):
        with st.spinner(&quot;Thinking...&quot;):
            response = generate_llama2_response(prompt)
            placeholder = st.empty()
            full_response = &apos;&apos;
            for item in response:
                full_response += item
                placeholder.markdown(full_response)
            placeholder.markdown(full_response)
    message = {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: full_response}
    st.session_state.messages.append(message)</code></pre><h3 id="21-model-setup">2.1 Model Setup</h3><p>In the code, firstly tweak the params per your hardware, models and objectives:</p><pre><code class="language-py">llama_model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;

n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.</code></pre><p>The free version of Colab does not have too much memory so here the&#xA0;<code>llama-2-7b-chat.Q5_0.gguf</code>&#xA0;is used but you can use a larger model for better performance.</p><h3 id="22-vector-database">2.2 Vector Database</h3><p>In order to perform RAG, a vector database has to be created first, in this example, the code read the&#xA0;<a href="https://vincentyuan.us/r/7344937c?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost">regulation B</a>&#xA0;and&#xA0;<a href="https://vincentyuan.us/r/311211cf?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost">regulation Z</a>&#xA0;PDFs and embed them, then a vector database is created based on that:</p><pre><code class="language-py">
# ====================== RAG ======================

# Encoding the PDFs
pdf_folder_path = &apos;/gdrive/MyDrive/Research/Data/GenAI/PDFs&apos;

loader = PyPDFDirectoryLoader(pdf_folder_path)

documents = loader.load()

#splitting the text into
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(documents)

# Create vector DB, embed and store the texts
# Supplying a persist_directory will store the embeddings on disk
persist_directory = &apos;db&apos;

## here we are using OpenAI embeddings but in future we will swap out to local embeddings
embedding = HuggingFaceEmbeddings()

vectordb = Chroma.from_documents(documents=texts,
                                 embedding=embedding,
                                 persist_directory=persist_directory)

retriever = vectordb.as_retriever(search_kwargs={&quot;k&quot;: 5})

</code></pre><h3 id="23-message-management">2.3 Message Management</h3><p>Then, these are the setup for the display/clear of messages of the chatbot:</p><pre><code class="language-py"># Store LLM generated responses
if &quot;messages&quot; not in st.session_state.keys():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]

# Display or clear chat messages
for message in st.session_state.messages:
    with st.chat_message(message[&quot;role&quot;]):
        st.write(message[&quot;content&quot;])

def clear_chat_history():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]
st.sidebar.button(&apos;Clear Chat History&apos;, on_click=clear_chat_history)</code></pre><h3 id="24-get-llm-response">2.4 Get LLM Response</h3><p>Below function appends the chat history into the prompt and use the vector database created above to retrieve answers.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Note that this QA chain is different from a regular LLM chain.</div></div><pre><code class="language-py"># Function for generating LLaMA2 response based on RAG.
def generate_llama2_response(prompt_input):

    pre_prompt = &quot;&quot;&quot;[INST] &lt;&lt;SYS&gt;&gt;
                  You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.

                  If you cannot answer the question from the given documents, please state that you do not have an answer.\n
                  &quot;&quot;&quot;


    for dict_message in st.session_state.messages:
        if dict_message[&quot;role&quot;] == &quot;user&quot;:
            pre_prompt += &quot;User: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;
        else:
            pre_prompt += &quot;Assistant: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;

    prompt = pre_prompt +  &quot;{context}User : {question}&quot; + &quot;[\INST]&quot;
    llama_prompt = PromptTemplate(template=prompt, input_variables=[&quot;context&quot;,&quot;question&quot;])


    qa_chain = RetrievalQA.from_chain_type(
        llm,
        retriever=retriever,
         chain_type_kwargs={&quot;prompt&quot;: llama_prompt}
    )

    result = qa_chain.run({
                            &quot;query&quot;: prompt_input})


    return result</code></pre><h3 id="25-conversation">2.5 Conversation</h3><p>Below shows the question and answering process, the chatbot responses to users&apos; questions:</p><pre><code class="language-py"># User-provided prompt
if prompt := st.chat_input():
    st.session_state.messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt})
    with st.chat_message(&quot;user&quot;):
        st.write(prompt)

# Generate a new response if last message is not from assistant
if st.session_state.messages[-1][&quot;role&quot;] != &quot;assistant&quot;:
    with st.chat_message(&quot;assistant&quot;):
        with st.spinner(&quot;Thinking...&quot;):
            response = generate_llama2_response(prompt)
            placeholder = st.empty()
            full_response = &apos;&apos;
            for item in response:
                full_response += item
                placeholder.markdown(full_response)
            placeholder.markdown(full_response)
    message = {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: full_response}
    st.session_state.messages.append(message)</code></pre><h2 id="3-start-the-chatbot">3 Start the Chatbot</h2><p>You can bring up the chatbot by using below command:</p><pre><code class="language-py">!streamlit run app.py --server.address=localhost &amp;&gt;/content/logs.txt &amp;

import urllib
print(&quot;Password/Enpoint IP for localtunnel is:&quot;,urllib.request.urlopen(&apos;https://ipv4.icanhazip.com&apos;).read().decode(&apos;utf8&apos;).strip(&quot;\n&quot;))

!npx localtunnel --port 8501</code></pre><p>The result shows a password to access the web app:</p><pre><code class="language-py">Password/Enpoint IP for localtunnel is: 34.125.220.166
npx: installed 22 in 2.393s
your url is: https://hot-pets-chew.loca.lt</code></pre><p>Go to that url and enter the password, and enjoy the time!</p><h2 id="4-summary">4 Summary</h2><p>This post demonstrates the construction of a versatile chatbot capable of more than just conversation. Specifically, it covers the following key features:</p><ul><li>Creation of a vector database utilizing domain knowledge.</li><li>Ability of the chatbot to retrieve information from the vector database and respond to user queries.</li><li>User-friendly interface for ease of use.</li></ul><p>This approach is scalable across various applications, as chatbots excel in information retrieval when equipped with a reliable database as the source of truth. Stay tuned for further insights into valuable applications of this technology.</p>]]></content:encoded></item><item><title><![CDATA[Unveiling the Deal: What Happens When Companies Merge]]></title><description><![CDATA[Company merger 101.]]></description><link>https://realvincentyuan.github.io/Spacecraft/unveiling-the-deal-what-happens-when-companies-merge/</link><guid isPermaLink="false">668afcbeac15d470add4a51c</guid><category><![CDATA[Pro]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 07 Jul 2024 20:40:17 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1715398947083-9274b5a00a5b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDExfHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjI5fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1715398947083-9274b5a00a5b?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDExfHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjI5fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Unveiling the Deal: What Happens When Companies Merge"><p>This post is to go through the most important processes in the merger of companies and answer most interested questions for employees, shareholders and customers!</p><h2 id="1-company-merger-process">1 Company Merger Process</h2><p>Acquiring a company in the U.S. is a complex process with various stages and potential outcomes. Here&apos;s a breakdown of the typical steps and what you can expect:</p><p><strong>1. Pre-Negotiation:</strong></p><ul><li><strong>Target Identification:</strong>&#xA0;The acquiring company identifies potential targets based on strategic fit, market potential, and other criteria.</li><li><strong>Initial Contact:</strong>&#xA0;Discreet inquiries are made to gauge interest and gather information.</li><li><strong>Non-Disclosure Agreement (NDA):</strong>&#xA0;Both parties sign an NDA to protect confidential information during discussions.</li></ul><p><strong>2. Due Diligence:</strong></p><ul><li><strong>In-depth Investigation:</strong>&#xA0;The acquiring company assesses the target&apos;s financial health, operations, legal status, and other critical factors.</li><li><strong>Valuation:</strong>&#xA0;Financial experts determine the target company&apos;s fair market value.</li></ul><p><strong>3. Negotiation and Agreement:</strong></p><ul><li><strong>Letter of Intent (LOI):</strong>&#xA0;A non-binding agreement outlining key terms like price, structure, and timelines.</li><li><strong>Negotiation:</strong>&#xA0;Both sides negotiate the final terms of the acquisition agreement, including purchase price, payment methods, and deal structure.</li><li><strong>Definitive Agreement:</strong>&#xA0;A legally binding document outlining all agreed-upon terms and conditions.</li></ul><p><strong>4. Regulatory Approvals:</strong></p><ul><li><strong>Antitrust Review:</strong>&#xA0;The deal might require approval from the Federal Trade Commission (FTC) or other regulatory bodies to ensure fair competition.</li><li><strong>Industry-Specific Approvals:</strong>&#xA0;Depending on the industry, further regulatory approvals might be necessary.</li></ul><p><strong>5. Closing and Integration:</strong></p><ul><li><strong>Closing:</strong>&#xA0;All legal formalities are completed, and the acquisition is finalized.</li><li><strong>Integration:</strong>&#xA0;The acquiring company integrates the target&apos;s operations, employees, and systems into its own structure. This can be a complex and lengthy process.</li></ul><p><strong>What to expect:</strong></p><ul><li><strong>Timeframe:</strong>&#xA0;The process can take months or even years, depending on the complexity of the deal and regulatory hurdles.</li><li><strong>Costs:</strong>&#xA0;Significant legal, financial, and integration costs are involved.</li><li><strong>Uncertainty:</strong>&#xA0;Regulatory approvals and market conditions can impact the deal&apos;s outcome.</li><li><strong>Impact:</strong>&#xA0;Acquisitions can affect employees, customers, and the industry at large.</li></ul><p><strong>Additional points to consider:</strong></p><ul><li>There are different types of acquisitions, such as stock purchases, asset purchases, and mergers. Each has its own nuances.</li><li>Friendly acquisitions involve cooperation between both parties, while hostile takeovers involve a more aggressive approach.</li><li>The specific process and outcomes can vary significantly depending on the size, industry, and circumstances of the companies involved.</li></ul><p>Now, let&apos;s break down each process and dive deep into how each process works, with some examples.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5YmxvZ3xlbnwwfHx8fDE3MDg4MzIzMzl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200" class="kg-image" alt="Unveiling the Deal: What Happens When Companies Merge" loading="lazy" width="1200" height="800" srcset="https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5YmxvZ3xlbnwwfHx8fDE3MDg4MzIzMzl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5YmxvZ3xlbnwwfHx8fDE3MDg4MzIzMzl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1700779100884-824d4a9caece?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5YmxvZ3xlbnwwfHx8fDE3MDg4MzIzMzl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200 1200w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by&#xA0;</span><a href="https://vincentyuan.us/r/b178b8d8?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;">&#xA0;/&#xA0;</span><a href="https://vincentyuan.us/r/8d1e4da3?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="2-pre-negotiation">2 Pre-negotiation</h2><p>The pre-negotiation phase in a company acquisition lays the groundwork for a successful deal or identifies potential roadblocks early on. Here&apos;s a more detailed breakdown of this crucial stage:</p><p><strong>1. Target Identification:</strong></p><ul><li><strong>Strategic fit:</strong>&#xA0;Aligning the target&apos;s strengths and weaknesses with the acquirer&apos;s goals and existing business.</li><li><strong>Market potential:</strong>&#xA0;Assessing the target&apos;s market share, growth potential, and competitive landscape.</li><li><strong>Financial attractiveness:</strong>&#xA0;Analyzing profitability, debt levels, and valuation multiples.</li></ul><p><strong>Examples:</strong></p><ul><li><strong>Amazon&apos;s acquisition of Whole Foods:</strong>&#xA0;Focused on expanding Amazon&apos;s grocery delivery and brick-and-mortar presence.</li><li><strong>Disney&apos;s acquisition of Marvel Entertainment:</strong>&#xA0;Aimed at acquiring valuable intellectual property and expanding its superhero universe.</li></ul><p><strong>2. Initial Contact:</strong></p><ul><li><strong>Discreet approach:</strong>&#xA0;Using intermediaries, investment bankers, or direct contact depending on the situation and target receptivity.</li><li><strong>Information gathering:</strong>&#xA0;Gauging the target&apos;s general interest, financial health, and potential deal structure.</li><li><strong>Non-Disclosure Agreement (NDA):</strong>&#xA0;Protecting confidential information shared during discussions.</li></ul><p><strong>Example:</strong></p><ul><li><strong>Microsoft&apos;s acquisition of LinkedIn:</strong>&#xA0;Initial contact reportedly occurred through a mutual acquaintance who connected Satya Nadella and Jeff Weiner.</li></ul><p><strong>3. Due Diligence Preparation:</strong></p><ul><li><strong>Gathering internal resources:</strong>&#xA0;Assembling legal, financial, and operational teams for in-depth analysis.</li><li><strong>Developing a due diligence plan:</strong>&#xA0;Defining scope, timelines, and key areas of investigation.</li><li><strong>Negotiating access:</strong>&#xA0;Securing permission to review the target&apos;s financial records, contracts, and other sensitive information.</li></ul><p><strong>4. Non-Binding Negotiations:</strong></p><ul><li><strong>Indicative offer:</strong>&#xA0;Presenting a non-binding price range based on preliminary valuation and market conditions.</li><li><strong>Structure exploration:</strong>&#xA0;Discussing potential deal structures (stock purchase, asset purchase, merger) and their implications.</li><li><strong>Exclusivity agreement (optional):</strong>&#xA0;Granting the acquirer temporary exclusive negotiation rights in exchange for a fee.</li></ul><p><strong>Remember:</strong></p><ul><li>Pre-negotiation is a delicate dance between expressing interest without revealing your hand too soon.</li><li>Thorough due diligence is crucial for understanding potential risks and opportunities.</li><li>Non-binding negotiations help refine deal terms and identify potential dealbreakers before investing significant resources.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1708363794493-75fa8284b934?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDIwfHx2eWJsb2d8ZW58MHx8fHwxNzA4ODMyMzM5fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200" class="kg-image" alt="Unveiling the Deal: What Happens When Companies Merge" loading="lazy" width="1200" height="800" srcset="https://images.unsplash.com/photo-1708363794493-75fa8284b934?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDIwfHx2eWJsb2d8ZW58MHx8fHwxNzA4ODMyMzM5fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1708363794493-75fa8284b934?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDIwfHx2eWJsb2d8ZW58MHx8fHwxNzA4ODMyMzM5fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1708363794493-75fa8284b934?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDIwfHx2eWJsb2d8ZW58MHx8fHwxNzA4ODMyMzM5fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200 1200w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by&#xA0;</span><a href="https://vincentyuan.us/r/1a28f81d?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;">&#xA0;/&#xA0;</span><a href="https://vincentyuan.us/r/8365405a?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="3-due-diligence">3 Due Diligence</h2><p>Due diligence is a crucial step in the company merger process, allowing the acquiring company to gain a deep understanding of the target company&apos;s financial health, operations, legal status, and potential risks. Here&apos;s a more specific breakdown of how it typically works:</p><p><strong>Stages of Due Diligence:</strong></p><p><strong>1. Pre-Diligence:</strong></p><ul><li>Initial research and information gathering about the target company.</li><li>Signing a Non-Disclosure Agreement (NDA) to protect confidential information.</li></ul><p><strong>2. Financial Due Diligence:</strong></p><ul><li>Reviewing financial statements, tax returns, and internal controls.</li><li>Assessing the company&apos;s financial performance, profitability, and debt levels.</li><li>Identifying potential financial risks and liabilities.</li></ul><p><strong>3. Operational Due Diligence:</strong></p><ul><li>Evaluating the target company&apos;s business operations, processes, and systems.</li><li>Analyzing market position, competitive landscape, and customer base.</li><li>Identifying potential operational challenges and opportunities.</li></ul><p><strong>4. Legal Due Diligence:</strong></p><ul><li>Reviewing legal documents, contracts, and intellectual property rights.</li><li>Assessing potential legal risks, compliance issues, and litigation exposure.</li><li>Ensuring the target company is operating legally and has a clear title to assets.</li></ul><p><strong>5. Environmental Due Diligence:</strong></p><ul><li>Assessing potential environmental liabilities and regulatory compliance.</li><li>Identifying any environmental hazards or contamination on the target company&apos;s property.</li></ul><p><strong>6. Human Resources Due Diligence:</strong></p><ul><li>Evaluating the target company&apos;s workforce, employee contracts, and labor relations.</li><li>Identifying potential human resource risks and liabilities, such as employee lawsuits or unionization efforts.</li></ul><p><strong>Additional Points:</strong></p><ul><li>The specific scope and depth of due diligence vary depending on the size and complexity of the deal.</li><li>Experienced professionals, such as accountants, lawyers, and consultants, are often involved in the process.</li><li>Due diligence findings can impact the negotiation of the deal terms and price.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1703641851886-1cd864d6efce?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDc2fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODk1NDY1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200" class="kg-image" alt="Unveiling the Deal: What Happens When Companies Merge" loading="lazy" width="1200" height="800" srcset="https://images.unsplash.com/photo-1703641851886-1cd864d6efce?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDc2fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODk1NDY1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1703641851886-1cd864d6efce?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDc2fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODk1NDY1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1703641851886-1cd864d6efce?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDc2fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODk1NDY1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200 1200w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by&#xA0;</span><a href="https://vincentyuan.us/r/660f764c?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;">&#xA0;/&#xA0;</span><a href="https://vincentyuan.us/r/ab2d6bca?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="4-negotiation-and-agreement">4 Negotiation and Agreement</h2><p>The negotiation and agreement phase is arguably the most critical stage in an acquisition, where the terms are hammered out and the deal&apos;s fate is determined. Here&apos;s an in-depth look at how it typically unfolds:</p><p><strong>1. Letter of Intent (LOI):</strong></p><ul><li><strong>Non-binding document outlining key deal terms:</strong>&#xA0;Price, structure, timelines, contingencies, and exclusivity provisions.</li><li><strong>Serves as a roadmap for further negotiations:</strong>&#xA0;Prevents wasting time if fundamental differences exist.</li><li><strong>May include break-up fees:</strong>&#xA0;To compensate the target if the deal falls through due to the acquirer&apos;s actions.</li></ul><p><strong>Example:</strong></p><ul><li><strong>SoftBank&apos;s acquisition of WeWork:</strong>&#xA0;The complex LOI included contingencies based on WeWork&apos;s financial performance.</li></ul><p><strong>2. Negotiation of Definitive Agreement:</strong></p><ul><li><strong>Intensive process involving lawyers, advisors, and executives:</strong>Each side advocates for their best interests.</li><li><strong>Key areas of negotiation:</strong>&#xA0;Purchase price, payment structure, warranties, indemnification, employee-related matters, and regulatory approvals.</li><li><strong>Back-and-forth through drafts and revisions:</strong>&#xA0;Striving for a mutually beneficial agreement.</li></ul><p><strong>3. Deal Sweeteners:</strong></p><ul><li><strong>Non-cash consideration:</strong>&#xA0;Stock, earn-outs, or other creative structures to bridge valuation gaps.</li><li><strong>Management incentives:</strong>&#xA0;Retention packages or equity grants to key employees.</li></ul><p><strong>Examples:</strong></p><ul><li><strong>Disney&apos;s acquisition of 21st Century Fox:</strong>&#xA0;Included a complex stock-based deal structure.</li><li><strong>Elon Musk&apos;s acquisition of Twitter:</strong>&#xA0;Involved offering severance packages to some employees.</li></ul><p><strong>4. Finalizing the Agreement:</strong></p><ul><li><strong>Legal review and approvals by boards and shareholders:</strong>Ensuring compliance and alignment.</li><li><strong>Signing ceremony:</strong>&#xA0;Formalizing the agreement and marking a significant milestone.</li></ul><p><strong>Additional Points:</strong></p><ul><li>Negotiation is a dynamic process with power struggles and potential deadlocks.</li><li>Effective communication, flexibility, and a win-win mindset are crucial for success.</li><li>Cultural differences and regulatory complexities can add layers to the process.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1703641852531-45e588841a21?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5MTIxOHxlbnwwfHx8fDE3MDg4MzYzMTN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200" class="kg-image" alt="Unveiling the Deal: What Happens When Companies Merge" loading="lazy" width="1200" height="1800" srcset="https://images.unsplash.com/photo-1703641852531-45e588841a21?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5MTIxOHxlbnwwfHx8fDE3MDg4MzYzMTN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1703641852531-45e588841a21?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5MTIxOHxlbnwwfHx8fDE3MDg4MzYzMTN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1703641852531-45e588841a21?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fHZ5MTIxOHxlbnwwfHx8fDE3MDg4MzYzMTN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200 1200w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by&#xA0;</span><a href="https://vincentyuan.us/r/3ec0a4a9?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;">&#xA0;/&#xA0;</span><a href="https://vincentyuan.us/r/010debcb?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="5-navigating-the-regulatory-maze">5 Navigating the Regulatory Maze</h2><p>Regulatory approval is a crucial hurdle in many acquisitions, aiming to ensure fair competition, consumer protection, and other societal considerations. Here&apos;s an overview of the process and common examples:</p><p><strong>1. Identifying Relevant Regulators:</strong></p><ul><li><strong>Industry-Specific Agencies:</strong>&#xA0;Depending on the industry, agencies like the Federal Trade Commission (FTC), Department of Justice (DOJ), or the Federal Communications Commission (FCC) might be involved.</li><li><strong>Antitrust Regulators:</strong>&#xA0;The FTC and DOJ hold primary authority for antitrust reviews to prevent mergers that reduce competition.</li><li><strong>Other Potential Regulators:</strong>&#xA0;Depending on the deal&apos;s specifics, agencies like the Securities and Exchange Commission (SEC) or state regulators might also weigh in.</li></ul><p><strong>2. Filing and Review Process:</strong></p><ul><li><strong>Filing:</strong>&#xA0;Companies submit detailed information about the merger, including market analyses and justifications.</li><li><strong>Initial Review:</strong>&#xA0;Regulators assess the potential impact on competition and other relevant factors.</li><li><strong>Second Request:</strong>&#xA0;If concerns arise, regulators can request more information and conduct deeper investigations.</li><li><strong>Public Comment:</strong>&#xA0;In some cases, the public can submit comments on the proposed merger.</li></ul><p><strong>3. Approval or Challenge:</strong></p><ul><li><strong>Clearance:</strong>&#xA0;If regulators determine no significant anti-competitive harms, they grant approval.</li><li><strong>Conditions:</strong>&#xA0;Approvals might come with conditions aimed at mitigating potential harms, like divestitures or restrictions on specific practices.</li><li><strong>Challenge:</strong>&#xA0;If regulators believe the deal violates competition laws, they can file lawsuits to block it.</li></ul><p><strong>4. Timeline:</strong></p><ul><li>The process can vary significantly depending on the complexity of the deal and the level of scrutiny required. It can take anywhere from weeks to months, or even years in complex cases.</li></ul><p><strong>Examples:</strong></p><ul><li><strong>AT&amp;T&apos;s attempted acquisition of T-Mobile:</strong>&#xA0;The DOJ blocked the merger due to concerns about reduced competition in the wireless market.</li><li><strong>Facebook&apos;s acquisition of WhatsApp:</strong>&#xA0;The FTC initially challenged the deal but ultimately approved it with conditions.</li></ul><p><strong>Additional Points:</strong></p><ul><li>The regulatory landscape can be complex and constantly evolving, requiring expert legal counsel for navigating the process.</li><li>The level of scrutiny and potential challenges can significantly impact the deal timeline and feasibility.</li><li>Understanding the regulatory environment and proactively addressing potential concerns is crucial for a successful acquisition.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1703693218701-f9f226bea6e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200" class="kg-image" alt="Unveiling the Deal: What Happens When Companies Merge" loading="lazy" width="1200" height="800" srcset="https://images.unsplash.com/photo-1703693218701-f9f226bea6e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1703693218701-f9f226bea6e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1703693218701-f9f226bea6e4?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200 1200w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by&#xA0;</span><a href="https://vincentyuan.us/r/60c63f27?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;">&#xA0;/&#xA0;</span><a href="https://vincentyuan.us/r/7a86123b?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="6-closing-and-integration">6&#xA0;<strong>Closing and Integration</strong></h2><p>Closing and integration mark the final chapter in a company merger, but they bring their own set of challenges and complexities. Here&apos;s a detailed breakdown:</p><p><strong>Closing:</strong></p><ul><li><strong>Formalization:</strong>&#xA0;Final documents are signed, legal formalities are completed, and the acquisition officially closes.</li><li><strong>Regulatory Approvals:</strong>&#xA0;If required, all necessary regulatory approvals must be secured before closing.</li><li><strong>Funding and Payment:</strong>&#xA0;The acquiring company finalizes the payment to the target company, often in cash, stock, or a combination.</li><li><strong>Shareholder Votes:</strong>&#xA0;For public companies, shareholder approval might be required before closing.</li></ul><p><strong>Example:</strong></p><ul><li><strong>CVS Health&apos;s acquisition of Aetna:</strong>&#xA0;The deal closed in 2018 after receiving regulatory approval and shareholder votes from both companies.</li></ul><p><strong>Integration:</strong></p><ul><li><strong>Combining Operations:</strong>&#xA0;Merging business functions, systems, and teams from both companies.</li><li><strong>Cultural Integration:</strong>&#xA0;Aligning company cultures, values, and communication styles.</li><li><strong>Employee Transitions:</strong>&#xA0;Addressing employee concerns, managing potential layoffs, and implementing training programs.</li><li><strong>Synergy Realization:</strong>&#xA0;Identifying and capturing cost savings, revenue growth, and other value-creation opportunities.</li></ul><p><strong>Challenges and Risks:</strong></p><ul><li><strong>Integration complexity:</strong>&#xA0;Cultural clashes, resistance to change, and IT system integration issues can be difficult to overcome.</li><li><strong>Synergy realization:</strong>&#xA0;Achieving projected synergies can be slower and more challenging than anticipated.</li><li><strong>Employee morale and retention:</strong>&#xA0;Managing employee anxiety, skills gaps, and potential talent loss during integration is crucial.</li></ul><p><strong>Examples:</strong></p><ul><li><strong>Disney&apos;s acquisition of Fox:</strong>&#xA0;The integration process was complex due to the size and diverse businesses involved.</li><li><strong>Kraft Heinz&apos;s acquisition of Unilever:</strong>&#xA0;The merger failed to achieve expected synergies and led to cultural clashes.</li></ul><p><strong>Additional Points:</strong></p><ul><li>Effective communication, change management strategies, and strong leadership are crucial for successful integration.</li><li>The integration process can take months or even years, and requires ongoing monitoring and adjustments.</li><li>The success of a merger ultimately hinges on a smooth and well-executed closing and integration phase.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1708363794973-79d264ca534e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDU0fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200" class="kg-image" alt="Unveiling the Deal: What Happens When Companies Merge" loading="lazy" width="1200" height="800" srcset="https://images.unsplash.com/photo-1708363794973-79d264ca534e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDU0fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1708363794973-79d264ca534e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDU0fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1708363794973-79d264ca534e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDU0fHx2eTEyMTh8ZW58MHx8fHwxNzA4ODM2MzMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1200 1200w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">Photo by&#xA0;</span><a href="https://vincentyuan.us/r/19e7420b?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Vincent Yuan @USA</span></a><span style="white-space: pre-wrap;">&#xA0;/&#xA0;</span><a href="https://vincentyuan.us/r/733d99ba?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost"><span style="white-space: pre-wrap;">Unsplash</span></a></figcaption></figure><h2 id="7-frequently-asked-questions">7 Frequently Asked Questions</h2><p>Here are some of the most commonly asked questions about company mergers from the perspectives of employees, shareholders and customers:</p><h3 id="employees">Employees</h3><p>For sure, the job security is the no.1 question. During a company merger, the evaluation of&#xA0;<strong>employee jobs</strong>&#xA0;typically involves several considerations. Let&#x2019;s explore this from different angles:</p><p><strong>Internal Assessment by the Merging Companies:</strong></p><ul><li>The merging companies themselves evaluate employee roles, responsibilities, and skills. They assess which positions are redundant, which are critical, and which can be integrated.</li><li><strong>Job evaluations</strong>&#xA0;may involve comparing job descriptions, performance records, and qualifications.</li></ul><p><strong>Consulting Companies or HR Experts:</strong></p><ul><li>Some mergers engage external consulting firms or HR experts to assist in evaluating employees.</li><li>These experts analyze factors such as job functions, competencies, and market value.</li><li>They may provide recommendations on retaining key talent, aligning compensation, and managing workforce transitions.</li></ul><p><strong>Retention of Key Employees:</strong></p><ul><li>Identifying and retaining&#xA0;<strong>key employees</strong>&#xA0;is crucial. These are individuals with specialized skills, institutional knowledge, or leadership roles.</li><li>Companies consider factors like expertise, client relationships, and strategic importance.</li></ul><p><strong>Redundancies and Layoffs:</strong></p><ul><li>Unfortunately, some positions become redundant due to overlapping functions after the merger.</li><li>Companies decide which roles to eliminate based on business needs, cost savings, and efficiency.</li><li><strong>Severance packages</strong>&#xA0;may be offered to affected employees.</li></ul><p><strong>Skill Assessment and Fit:</strong></p><ul><li>Companies evaluate whether employees&#x2019; skills align with the merged organization&#x2019;s goals.</li><li>They consider adaptability, willingness to learn, and cultural fit.</li></ul><h3 id="shareholders">Shareholders</h3><p>This is a breakdown to show how&#xA0;<strong>shareholders</strong>&#xA0;are impacted during a company merger:</p><p><strong>Exchange of Shares:</strong></p><ul><li>In a&#xA0;<strong>stock-for-stock merger</strong>, shareholders of both companies receive shares in the new combined entity.</li><li>The&#xA0;<strong>exchange ratio</strong>&#xA0;determines whether one company&#x2019;s shareholders receive a premium above their share price before the merger announcement.</li><li>If the merger is favorable, shares of both companies may rise.</li></ul><p><strong>Dilution of Control:</strong></p><ul><li>Shareholders whose shares are&#xA0;<strong>not exchanged</strong>&#xA0;find their control diluted.</li><li>New shares issued to the other company&#x2019;s shareholders reduce the control of existing shareholders.</li></ul><p><strong>Temporary Volatility:</strong></p><ul><li>Shareholders of the&#xA0;<strong>acquiring firm</strong>&#xA0;may experience a&#xA0;<strong>temporary drop</strong>&#xA0;in share value before the merger.</li><li>Shareholders of the target firm may see a rise in share value during the period.</li></ul><h3 id="customers">Customers</h3><p>Certainly! Let&#x2019;s break down how&#xA0;<strong>customers</strong>&#xA0;are impacted during a company merger:aa</p><p><strong>Service Disruptions and Miscommunications:</strong></p><ul><li><strong>Integration efforts</strong>&#xA0;can divert attention from day-to-day operations, leading to&#xA0;<strong>miscommunications</strong>&#xA0;with customers.</li><li>Poorly managed systems migrations may cause confusion or delays in service.</li></ul><p><strong>Changes in Customer Service:</strong></p><ul><li><strong>Customer service</strong>&#xA0;levels may fluctuate due to adjustments in staff, processes, or technology.</li><li>Customers might experience longer wait times or inconsistent support.</li></ul><p><strong>Product and Service Offerings:</strong></p><ul><li><strong>Choices</strong>&#xA0;available to customers may change.</li><li>Some products or services may be&#xA0;<strong>discontinued</strong>, while new ones may be introduced.</li></ul><p><strong>Pricing and Terms:</strong></p><ul><li><strong>Pricing structures</strong>&#xA0;could shift. Customers may face price increases or discounts.</li><li><strong>Contract terms</strong>&#xA0;might be modified, affecting existing agreements.</li></ul><p><strong>Brand Perception and Loyalty:</strong></p><ul><li>Mergers can&#xA0;<strong>stress relationships</strong>&#xA0;with customers.</li><li>Brand loyalty may be tested as customers adapt to the new entity.</li></ul><p><strong>Communication Efforts:</strong></p><ul><li><strong>Effective communication</strong>&#xA0;about the merger&#x2019;s benefits and changes is crucial.</li><li>Transparency helps maintain customer trust.</li></ul><h2 id="reference">Reference</h2><ul><li><strong>Investopedia: Mergers &amp; Acquisitions:</strong><a href="https://vincentyuan.us/r/518d4ce2?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost" rel="noopener noreferrer">https://www.investopedia.com/terms/m/mergersandacquisitions.asp</a></li><li><strong>Harvard Business Review: The Art of the Deal:</strong><a href="https://vincentyuan.us/r/e2ed8325?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost" rel="noopener noreferrer">https://hbr.org/podcast/2016/02/the-art-of-the-interview</a></li><li><strong>Mergers &amp; Acquisitions Journal:</strong>&#xA0;<a href="https://vincentyuan.us/r/6acb3dda?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost" rel="noopener noreferrer">https://mergersandinquisitions.com/</a></li><li><strong>Department of Justice: Antitrust Division:</strong><a href="https://vincentyuan.us/r/8d743a68?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost" rel="noopener noreferrer">https://www.justice.gov/atr/</a></li><li><strong>Antitrust Source:</strong>&#xA0;<a href="https://vincentyuan.us/r/3ad13142?m=43db1032-e0f7-47ae-b55c-36ea838b6b54&amp;ref=localhost" rel="noopener noreferrer">https://www.antitrustsource.com/</a></li></ul>]]></content:encoded></item><item><title><![CDATA[Built a Chatbot with Streamlit and Llama 2 with Google Colab GPUs from Scratch]]></title><description><![CDATA[End to end chatbot development with Llama 2.]]></description><link>https://realvincentyuan.github.io/Spacecraft/built-a-chatbot-with-streamlit-and-llama-2-with-google-colab-gpus-from-scratch/</link><guid isPermaLink="false">668afae6ac15d470add4a506</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 07 Jul 2024 20:31:52 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1715394016216-f0c45a43ca69?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1715394016216-f0c45a43ca69?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Built a Chatbot with Streamlit and Llama 2 with Google Colab GPUs from Scratch"><p>So far, we have talked about a lot of things regarding Llama 2:</p><ul><li>Swift inference powered by GPUs</li><li>Thoughtful responses with appropriate prompts</li><li>Question answering utilizing a knowledge database</li><li>A user-friendly web interface</li></ul><p>You can find those informative posts in the&#xA0;<code>GenAI</code>&#xA0;section of Spacecraft as below:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://realvincentyuan.github.io/Spacecraft/tag/genai/index.html?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">GenAI - Spacecraft</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://t1.gstatic.com/faviconV2?client=SOCIAL&amp;type=FAVICON&amp;fallback_opts=TYPE,SIZE,URL&amp;url=https://github.io/Spacecraft/tag/genai/index.html&amp;size=128" alt="Built a Chatbot with Streamlit and Llama 2 with Google Colab GPUs from Scratch"><span class="kg-bookmark-author">Spacecraft</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1477959858617-67f85cf4f1df?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fGNoaWNhZ298ZW58MHx8fHwxNjg4OTQxMDIwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Built a Chatbot with Streamlit and Llama 2 with Google Colab GPUs from Scratch"></div></a></figure><p>This post shows a product that makes the best of all the things learned, and build a web-based chatbot powered by a local Llama 2 model, running on Google Colab with GPUs.</p><h2 id="2-dependencies">2 Dependencies</h2><p>Firstly, install a few dependencies:</p><pre><code class="language-py">!pip install -q streamlit

!npm install localtunnel

# GPU setup of LangChain
!CMAKE_ARGS=&quot;-DLLAMA_CUBLAS=on&quot; FORCE_CMAKE=1 pip install --force-reinstall llama-cpp-python==0.2.28  --no-cache-dir

!pip install huggingface_hub  chromadb langchain sentence-transformers pinecone_client</code></pre><p>Then download the Llama 2 model to the Colab notebook:</p><pre><code class="language-py">!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf</code></pre><h2 id="3-build-the-web-chatbot">3 Build the Web Chatbot</h2><p>The web chatbot is like this:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/llama_2_bot.png" class="kg-image" alt="Built a Chatbot with Streamlit and Llama 2 with Google Colab GPUs from Scratch" loading="lazy" width="2998" height="1918"><figcaption><span style="white-space: pre-wrap;">Llama 2 Chatbot</span></figcaption></figure><p>You need to write the app code to the disk first:</p><pre><code class="language-py">%%writefile app.py

import streamlit as st
import os

from langchain.llms import LlamaCpp
from langchain.chains import LLMChain
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate

from langchain.llms import LlamaCpp


# App title
st.set_page_config(page_title=&quot;&#x1F999;&#x1F4AC; Llama 2 Chatbot&quot;)

llama_model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;

n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.

# for token-wise streaming so you&apos;ll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])

# Replicate Credentials
with st.sidebar:
    st.title(&apos;&#x1F999;&#x1F4AC; Llama 2 Chatbot&apos;)


    st.subheader(&apos;Models and parameters&apos;)
    selected_model = st.sidebar.selectbox(&apos;Choose a Llama2 model&apos;, [&apos;Llama2-7B&apos;, &apos;Llama2-13B&apos;], key=&apos;selected_model&apos;)

    if selected_model == &apos;Llama2-7B&apos;:
        llm_path = llama_model_path
    elif selected_model == &apos;Llama2-13B&apos;:
        llm_path = llama_model_path

    temperature = st.sidebar.slider(&apos;temperature&apos;, min_value=0.01, max_value=5.0, value=0.1, step=0.01)
    top_p = st.sidebar.slider(&apos;top_p&apos;, min_value=0.01, max_value=1.0, value=0.9, step=0.01)
    max_length = st.sidebar.slider(&apos;max_length&apos;, min_value=32, max_value=128, value=120, step=8)
    st.markdown(&apos;&#x1F4D6; Learn how to build this app in this [blog](https://blog.streamlit.io/how-to-build-a-llama-2-chatbot/)!&apos;)


    llm = LlamaCpp(
      model_path=llm_path,
      temperature=temperature,
      top_p=top_p,
      n_ctx=2048,
      n_gpu_layers=n_gpu_layers,
      n_batch=n_batch,
      callback_manager=callback_manager,
      verbose=True,
    )

# Store LLM generated responses
if &quot;messages&quot; not in st.session_state.keys():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]

# Display or clear chat messages
for message in st.session_state.messages:
    with st.chat_message(message[&quot;role&quot;]):
        st.write(message[&quot;content&quot;])

def clear_chat_history():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]
st.sidebar.button(&apos;Clear Chat History&apos;, on_click=clear_chat_history)


# Function for generating LLaMA2 response. Refactored from https://github.com/a16z-infra/llama2-chatbot
def generate_llama2_response(prompt_input):

    pre_prompt = &quot;&quot;&quot;[INST] &lt;&lt;SYS&gt;&gt;
                  You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.

                  If you cannot answer the question from the given documents, please state that you do not have an answer.\n
                  &quot;&quot;&quot;


    for dict_message in st.session_state.messages:
        if dict_message[&quot;role&quot;] == &quot;user&quot;:
            pre_prompt += &quot;User: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;
        else:
            pre_prompt += &quot;Assistant: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;

    prompt = pre_prompt +  &quot;User : {question}&quot; + &quot;[\INST]&quot;
    llama_prompt = PromptTemplate(template=prompt, input_variables=[&quot;question&quot;])

    chain = LLMChain(llm=llm, prompt=llama_prompt)

    result = chain({
                &quot;question&quot;: prompt_input
                 })


    return result[&apos;text&apos;]

# User-provided prompt
if prompt := st.chat_input():
    st.session_state.messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt})
    with st.chat_message(&quot;user&quot;):
        st.write(prompt)

# Generate a new response if last message is not from assistant
if st.session_state.messages[-1][&quot;role&quot;] != &quot;assistant&quot;:
    with st.chat_message(&quot;assistant&quot;):
        with st.spinner(&quot;Thinking...&quot;):
            response = generate_llama2_response(prompt)
            placeholder = st.empty()
            full_response = &apos;&apos;
            for item in response:
                full_response += item
                placeholder.markdown(full_response)
            placeholder.markdown(full_response)
    message = {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: full_response}
    st.session_state.messages.append(message)</code></pre><h3 id="31-model-setup">3.1 Model Setup</h3><p>In the code, firstly tweak the params per your hardware, models and objectives:</p><pre><code class="language-py">llama_model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;

n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.</code></pre><p>The free version of Colab does not too much memory so here the&#xA0;<code>llama-2-7b-chat.Q5_0.gguf</code>&#xA0;is used but you can use a larger model for better performance.</p><h3 id="32-message-management">3.2 Message Management</h3><p>Then, these are the setup for the display/clear of messages of the chatbot:</p><pre><code class="language-py"># Store LLM generated responses
if &quot;messages&quot; not in st.session_state.keys():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]

# Display or clear chat messages
for message in st.session_state.messages:
    with st.chat_message(message[&quot;role&quot;]):
        st.write(message[&quot;content&quot;])

def clear_chat_history():
    st.session_state.messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]
st.sidebar.button(&apos;Clear Chat History&apos;, on_click=clear_chat_history)</code></pre><h3 id="33-get-llm-response">3.3 Get LLM Response</h3><p>Below function appends the chat history into the prompt and get the response of model:</p><pre><code class="language-py">def generate_llama2_response(prompt_input):

    pre_prompt = &quot;&quot;&quot;[INST] &lt;&lt;SYS&gt;&gt;
                  You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.

                  If you cannot answer the question from the given documents, please state that you do not have an answer.\n
                  &quot;&quot;&quot;


    for dict_message in st.session_state.messages:
        if dict_message[&quot;role&quot;] == &quot;user&quot;:
            pre_prompt += &quot;User: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;
        else:
            pre_prompt += &quot;Assistant: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;

    prompt = pre_prompt +  &quot;User : {question}&quot; + &quot;[\INST]&quot;
    llama_prompt = PromptTemplate(template=prompt, input_variables=[&quot;question&quot;])

    chain = LLMChain(llm=llm, prompt=llama_prompt)

    result = chain({
                &quot;question&quot;: prompt_input
                 })


    return result[&apos;text&apos;]</code></pre><h3 id="34-conversation">3.4 Conversation</h3><p>Below shows the question and answering process, the chatbot responses to users&apos; questions:</p><pre><code class="language-py"># User-provided prompt
if prompt := st.chat_input():
    st.session_state.messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt})
    with st.chat_message(&quot;user&quot;):
        st.write(prompt)

# Generate a new response if last message is not from assistant
if st.session_state.messages[-1][&quot;role&quot;] != &quot;assistant&quot;:
    with st.chat_message(&quot;assistant&quot;):
        with st.spinner(&quot;Thinking...&quot;):
            response = generate_llama2_response(prompt)
            placeholder = st.empty()
            full_response = &apos;&apos;
            for item in response:
                full_response += item
                placeholder.markdown(full_response)
            placeholder.markdown(full_response)
    message = {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: full_response}
    st.session_state.messages.append(message)</code></pre><h2 id="4-start-the-chatbot">4 Start the Chatbot</h2><p>You can bring up the chatbot by using below command:</p><pre><code class="language-py">!streamlit run app.py --server.address=localhost &amp;&gt;/content/logs.txt &amp;

import urllib
print(&quot;Password/Enpoint IP for localtunnel is:&quot;,urllib.request.urlopen(&apos;https://ipv4.icanhazip.com&apos;).read().decode(&apos;utf8&apos;).strip(&quot;\n&quot;))

!npx localtunnel --port 8501</code></pre><p>The result shows a password to access the web app:</p><pre><code class="language-py">Password/Enpoint IP for localtunnel is: 35.185.197.1
npx: installed 22 in 2.393s
your url is: https://hot-pets-chew.loca.lt</code></pre><p>Go to that url and enter the password, and enjoy the time!</p><h2 id="5-conclusion">5 Conclusion</h2><p>This post consolidates information to transform your local Llama 2 model into a fully functional chatbot. Moreover, you have the flexibility to craft specialized assistants for distinct domains by customizing the system prompts, all at no additional cost.</p><p>Let&apos;s build something cool!</p>]]></content:encoded></item><item><title><![CDATA[Question Answering on Multiple Files with Llama 2 and RAG]]></title><description><![CDATA[Question answering with multiple files using RAG.]]></description><link>https://realvincentyuan.github.io/Spacecraft/question-answering-on-multiple-files-with-llama-2-and-rag/</link><guid isPermaLink="false">668afa15ac15d470add4a4f4</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 07 Jul 2024 20:29:41 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1715394016216-f0c45a43ca69?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1715394016216-f0c45a43ca69?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ5fHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Question Answering on Multiple Files with Llama 2 and RAG"><p>In the previous post, we discussed the process of utilizing Llama 2 and retrieval augmented generation (RAG) for question answering. However, the method shared was designed for a single file, and in many scenarios, it&apos;s essential for the chatbot to have knowledge about all the information across multiple input files. This post will demonstrate how to achieve this capability with Llama 2 at no cost.</p><p>This post will show:</p><ul><li>Run Llama 2 with GPUs</li><li>Create a vector store based on multiple files</li><li>Question answering based on RAG with multiple files in the vector store</li></ul><h2 id="1-get-llama-2-ready">1 Get Llama 2 Ready</h2><p>Firstly, install Python dependencies, download the Llama 2 model, and load Llama 2 model. This part is identical to the reference link above so no details are shared repeatedly.</p><pre><code class="language-py">!CMAKE_ARGS=&quot;-DLLAMA_CUBLAS=on&quot; FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir

!pip install huggingface_hub   chromadb langchain sentence-transformers pinecone_client

import numpy as np
import pandas as pd

from huggingface_hub import hf_hub_download
from llama_cpp import Llama

from langchain.llms import LlamaCpp
from langchain.chains import LLMChain
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate

# Vector store
from langchain.document_loaders import DirectoryLoader, TextLoader
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain.vectorstores import Chroma

# Show result
import markdown

!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf

# for token-wise streaming so you&apos;ll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])

llama_model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;

n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.


llm = LlamaCpp(
    model_path=llama_model_path,
    temperature=0.1,
    top_p=1,
    n_ctx=16000,
    n_gpu_layers=n_gpu_layers,
    n_batch=n_batch,
    callback_manager=callback_manager,
    verbose=True,
)</code></pre><h2 id="2-create-vector-database">2 Create Vector Database</h2><p>Firstly, let&apos;s download some dataset:</p><pre><code class="language-py">!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip
!unzip -q new_articles.zip -d new_articles</code></pre><p>These are a bunch of news text files:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/files.png" class="kg-image" alt="Question Answering on Multiple Files with Llama 2 and RAG" loading="lazy" width="930" height="1532"><figcaption><span style="white-space: pre-wrap;">Input News Data</span></figcaption></figure><h3 id="21-load-files">2.1 Load Files</h3><p>Load the files using&#xA0;<code>DirectoryLoader</code>&#xA0;made by LangChain:</p><pre><code class="language-py">from langchain.text_splitter import RecursiveCharacterTextSplitter

loader = DirectoryLoader(&apos;./new_articles/&apos;, glob=&quot;./*.txt&quot;, loader_cls=TextLoader)

documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(documents)</code></pre><h3 id="22-create-the-database">2.2 Create the Database</h3><pre><code class="language-py">from langchain.embeddings import HuggingFaceEmbeddings


# Save the db in the disk
persist_directory = &apos;db&apos;

# HuggingFace embedding is free!
embedding = HuggingFaceEmbeddings()

vectordb = Chroma.from_documents(documents=texts, 
                                 embedding=embedding,
                                 persist_directory=persist_directory)</code></pre><p>You can save the database in the disk and load it back to the workflow in below ways:</p><pre><code class="language-py">vectordb.persist()
vectordb = None

vectordb = Chroma(persist_directory=persist_directory, 
                  embedding_function=embedding)</code></pre><h3 id="23-make-a-retriever">2.3 Make a Retriever</h3><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">The number of files to be searched impacts the result, the<code spellcheck="false" style="white-space: pre-wrap;">k</code>value is a parameter to tweak per your use case.</div></div><pre><code class="language-py">retriever = vectordb.as_retriever(search_kwargs={&quot;k&quot;: 5})</code></pre><h2 id="3-rag">3 RAG</h2><p>We then use&#xA0;<code>RetrievalQA</code>&#xA0;to retrieve the documents from the vector database and give the model more context on Llama 2, thereby increasing its knowledge.</p><p>Firstly, create the&#xA0;<code>qa_chain</code>:</p><pre><code class="language-py"># use another LangChain&apos;s chain, RetrievalQA, to associate Llama with the loaded documents stored in the vector db
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm,
    retriever=retriever
)</code></pre><p>Then let&apos;s ask a few questions regarding the input documents, here comes the 1st question:</p><pre><code class="language-py">query = &quot;Any news about Hugging Face and ServiceNow? Also include the source in the response.&quot;
llm_response = qa_chain(query)</code></pre><p>The result is like:</p><pre><code class="language-py">Hugging Face raised $35 million from investors including ServiceNow, according to TechCrunch on May 18, 2022. (Source: TechCrunch)</code></pre><p>Let&apos;s ask another question:</p><pre><code class="language-py">query = &quot;Any news about Google IO 2023? Also include the source in the response.&quot;
llm_response = qa_chain(query)</code></pre><p>The answer to the 2nd question is:</p><pre><code class="language-py">Based on the provided context, it seems that Google IO 2023 is expected to announce new hardware, including a foldable smartphone called Pixel Fold, and possibly a budget device called Pixel 7a, as well as updates to Wear OS and developer tools. Additionally, there may be news about Google&apos;s AI plans, with generative AI (like Bard) appearing across Google&apos;s line of products. However, I don&apos;t know the exact details or timeline of these announcements, as the provided context only provides general information about what to expect from the conference.</code></pre><h2 id="4-summary">4 Summary</h2><p>Up to this point, you can envision the possibilities that Llama 2 unlocks within this workflow, alongside other techniques highlighted in my blog. Notably, it encompasses:</p><ul><li>Swift inference powered by GPUs</li><li>Thoughtful responses with appropriate prompts</li><li>Question answering utilizing a knowledge database</li><li>A user-friendly web interface</li></ul><p>These building blocks empower developers to create more robust applications than ever before. Stay tuned for the unveiling of more exciting products!</p>]]></content:encoded></item><item><title><![CDATA[Job Aid of Running Streamlit App on Google Colab]]></title><description><![CDATA[<p>Streamlit is a user-friendly, open-source Python framework designed to effortlessly create and share interactive data applications. Whether you&apos;re a data scientist, engineer, or analyst, Streamlit empowers you to transform your scripts into robust web applications within minutes, all within the familiar Python environment.</p><p>Google Colab, on the other</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/job-aid-of-running-streamlit-app-on-google-colab/</link><guid isPermaLink="false">668af9abac15d470add4a4e7</guid><category><![CDATA[Tech]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 07 Jul 2024 20:26:08 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703644902501-4e1e9b207200?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQwfHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703644902501-4e1e9b207200?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQwfHx2eTEyMTh8ZW58MHx8fHwxNzIwMzgzNjQ1fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Job Aid of Running Streamlit App on Google Colab"><p>Streamlit is a user-friendly, open-source Python framework designed to effortlessly create and share interactive data applications. Whether you&apos;re a data scientist, engineer, or analyst, Streamlit empowers you to transform your scripts into robust web applications within minutes, all within the familiar Python environment.</p><p>Google Colab, on the other hand, provides a seamless environment for testing ideas related to app development, model training, and Gen AI experiments. It eliminates the need for manual setup of the coding environment and offers the added advantage of free GPUs.</p><p>The synergy between Streamlit and Google Colab becomes even more compelling when you can translate your demonstrations into interactive web applications. This enables you to effectively operationalize your ideas. In this post, we&apos;ll explore how to leverage Streamlit to build web applications seamlessly within the Google Colab environment.</p><h2 id="1-install-dependencies">1 Install Dependencies</h2><p>Firstly, install Streamlit:</p><pre><code class="language-py">!pip install -q streamlit</code></pre><p>Then install localtunnel to serve the Streamlit app</p><pre><code class="language-py">!npm install localtunnel</code></pre><h2 id="2-build-your-apps">2 Build Your Apps</h2><p>Create a demo web application like below:</p><pre><code class="language-py">%%writefile app.py

import streamlit as st

st.write(&apos;Hello, *World!* :sunglasses:&apos;)</code></pre><p>Then run the app using below command:</p><pre><code class="language-py">!streamlit run app.py --server.address=localhost &amp;&gt;/content/logs.txt &amp;</code></pre><p>And a few files should be created and shown like this:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/streamlit.png" class="kg-image" alt="Job Aid of Running Streamlit App on Google Colab" loading="lazy" width="2204" height="734"><figcaption><span style="white-space: pre-wrap;">File System</span></figcaption></figure><h2 id="3-expose-the-app">3 Expose the App</h2><p>Let&apos;s expose the app to the port 8051:</p><pre><code class="language-py">import urllib
print(&quot;Password/Enpoint IP for localtunnel is:&quot;,urllib.request.urlopen(&apos;https://ipv4.icanhazip.com&apos;).read().decode(&apos;utf8&apos;).strip(&quot;\n&quot;))

!npx localtunnel --port 8501</code></pre><p>The return will be like this:</p><pre><code class="language-py">Password/Enpoint IP for localtunnel is: 35.245.122.211
npx: installed 22 in 1.71s
your url is: https://itchy-bikes-smoke.loca.lt</code></pre><p>Copy that password, and click the url, it will lead you to a page:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/raw_web.png" class="kg-image" alt="Job Aid of Running Streamlit App on Google Colab" loading="lazy" width="1768" height="841"><figcaption><span style="white-space: pre-wrap;">Landing Page</span></figcaption></figure><p>Once your enter the password, the web app is now yours:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/streamlit_app.png" class="kg-image" alt="Job Aid of Running Streamlit App on Google Colab" loading="lazy" width="1132" height="460"><figcaption><span style="white-space: pre-wrap;">The Hello World App</span></figcaption></figure><h2 id="4-conclusion">4 Conclusion</h2><p>This job aid shows how you can build a web app within Google Colab, now you can move one step further and try to build something cool &#x1F60E;</p>]]></content:encoded></item><item><title><![CDATA[How to Prompt Correctly with Llama 2?]]></title><description><![CDATA[Some learnings with prompting to Llama 2.]]></description><link>https://realvincentyuan.github.io/Spacecraft/how-to-prompt-correctly-with-llama-2/</link><guid isPermaLink="false">668a1b22ac15d470add4a2e3</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 28 Jan 2024 04:26:24 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="How to Prompt Correctly with Llama 2?"><p>Uncertain if you&apos;ve encountered instances where Llama 2 provides irrelevant, redundant, or potentially harmful responses. Such outcomes can be perplexing and may lead users to disengage. A contributing factor to this issue is often the incorrect utilization of prompts. Therefore, this post aims to introduce best practices for prompting when developing GenAI apps with Llama 2.</p><p>The sample code can run on Google Colab with GPUs, kindly check below post for the GPU configuration of Llama 2.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://realvincentyuan.github.io/Spacecraft/run-llama-2-with-retrieval-augmented-generation-rag-in-google-colab-with-gpus/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs</div><div class="kg-bookmark-description">Run Llama2 with RAG in Google Colab.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://realvincentyuan.github.io/Spacecraft/favicon.ico" alt="How to Prompt Correctly with Llama 2?"><span class="kg-bookmark-author">Spacecraft</span><span class="kg-bookmark-publisher">Vincent Yuan</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1677756119517-756a188d2d94?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDR8fGFpfGVufDB8fHx8MTcwMTYzNjU4OHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="How to Prompt Correctly with Llama 2?"></div></a></figure><p>This post will show:</p><ul><li>Run Llama 2 with GPUs</li><li>Comparison of different prompts and the impact to the response of Llama 2</li><li>Prompt design for chat, with awareness of historical messages</li></ul><h2 id="1-get-llama-2-ready">1 Get Llama 2 Ready</h2><p>Firstly, install Python dependencies, download the Llama 2 model, and load Llama 2 model. This part is identical to the reference link above so no details are shared repeatedly.</p><pre><code class="language-py">!CMAKE_ARGS=&quot;-DLLAMA_CUBLAS=on&quot; FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir

!pip install huggingface_hub   chromadb langchain sentence-transformers pinecone_client

import numpy as np
import pandas as pd

from huggingface_hub import hf_hub_download
from llama_cpp import Llama

from langchain.llms import LlamaCpp
from langchain.chains import LLMChain
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate

# Vector store
from langchain.document_loaders import CSVLoader
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain.vectorstores import Chroma

# Show result
import markdown

!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf

# for token-wise streaming so you&apos;ll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])

llama_model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;

n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.

from langchain.llms import LlamaCpp
llm = LlamaCpp(
    model_path=llama_model_path,
    temperature=0.1,
    top_p=1,
    n_ctx=16000,
    n_gpu_layers=n_gpu_layers,
    n_batch=n_batch,
    callback_manager=callback_manager,
    verbose=True,
)</code></pre><h2 id="2-impact-of-different-prompts">2 Impact of Different Prompts</h2><p>It is pretty amazing that slightly different prompts will lead to quite different response. This can be reflected by simple testing as below.</p><h3 id="21-just-ask-questions">2.1 Just Ask Questions</h3><p>For instance, the most straightforward way is just to ask what you want like below:</p><pre><code class="language-py">Testing_message = &quot;The Stoxx Europe 600 index slipped 0.5% at the close, extending a lackluster start to the year.&quot;

# Use LangChain&apos;s PromptTemplate and LLMChain
prompt = PromptTemplate.from_template(
    &quot;Extract the named entity information from below text: {text}&quot;
)

chain = LLMChain(llm=llm, prompt=prompt)
answer = chain.invoke(Testing_message)</code></pre><p>The answer is like below:</p><pre><code class="language-py"> The index has fallen 3.7% since the beginning of January and is down 12.9% from its peak in August last year.
Please provide the named entities as follows:
1. Stoxx Europe 600
2. index
3. Europe
4. January
5. August</code></pre><p>As you can see, Llama 2 firstly repeats the sentence and also adds more info, then answers the question, which is not expected by users as it seems to be out of control in a sense.</p><h3 id="22-prompt-with-system-message">2.2 Prompt with System Message</h3><p>By slightly adjusting the prompt, the response will become more normal.</p><pre><code class="language-py">prompt = PromptTemplate.from_template(
    &quot;[INST]Extract the important Named Entity Recoginiton information from this text: {text}, do not add unrelated content in the reply.[/INST]&quot;
)
chain = LLMChain(llm=llm, prompt=prompt)
answer = chain.invoke(Testing_message)</code></pre><p>The response becomes:</p><pre><code class="language-py">  Sure! Here are the important named entities recognized in the given text:

1. Stoxx Europe 600 - Index
2. Europe - Continent</code></pre><p>So now it does not change the sentence, and only answers the question that user asks. This version makes more sense simply because the addition of <code>[INST]</code> and <code>[/INST]</code> in the prompt. <code>[INST]</code> is part of the token used in the model training process, shared in the <a href="https://huggingface.co/papers/2307.09288?ref=localhost">Llama 2 paper</a>, which helps model understand the conversation.</p><p>Also, there is a more flexible way to do this, also with the addition of customizable system message as below:</p><pre><code class="language-py"># creating prompt for large language model
pre_prompt = &quot;&quot;&quot;[INST] &lt;&lt;SYS&gt;&gt;
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.

If you cannot answer the question from the given documents, please state that you do not have an answer.\n
&quot;&quot;&quot;

prompt = pre_prompt + &quot;{context}\n&quot; +&quot;Question : {question}&quot; + &quot;[\INST]&quot;
llama_prompt = PromptTemplate(template=prompt, input_variables=[&quot;context&quot;, &quot;question&quot;])

chain = LLMChain(llm=llm, prompt=llama_prompt)

result = chain({ &quot;context&quot; : &quot;Extract the named entity information from below sentences:&quot;,
                &quot;question&quot;: Testing_message
                 })</code></pre><p>The result is as below:</p><pre><code class="language-py">  Sure, I&apos;d be happy to help! Here is the named entity information extracted from the sentence you provided:

* Stoxx Europe 600 index
* Europe
* year

I hope this helps! Let me know if you have any other questions.</code></pre><p>In fact this is the template strictly following the training procedure of Llama 2. And with above template, you can customize the system message more flexibly though the response might look similar to a simplified version as shown above.</p><pre><code class="language-py">&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;
{{ system_prompt }}
&lt;&lt;/SYS&gt;&gt;

{{ user_message }} [/INST]
</code></pre><h3 id="23-prompt-with-chat-history">2.3 Prompt with Chat History</h3><p>Llama 2 does not have memory, using above prompt would not allow the model to answer your question based on the chat history, in order to address this challenge, we need to embed the chat history into the prompt so that the model is exposed to it.</p><p>Below is a vanilla version that works, firstly have the 1st round the question &amp; answering:</p><pre><code class="language-py">def create_chat_prompt(pre_prompt, chat_messages):
  for dict_message in chat_messages:
      if dict_message[&quot;role&quot;] == &quot;user&quot;:
          pre_prompt += &quot;User: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;
      else:
          pre_prompt += &quot;Assistant: &quot; + dict_message[&quot;content&quot;] + &quot;\n\n&quot;


  prompt = pre_prompt + &quot;User : {question}&quot; + &quot;[\INST]&quot;
  return prompt

messages = [{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;How may I assist you today?&quot;}]

# creating prompt for large language model
pre_prompt = &quot;&quot;&quot;[INST] &lt;&lt;SYS&gt;&gt;
You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.

If you cannot answer the question from the given documents, please state that you do not have an answer.\n
&quot;&quot;&quot;


llama_chat_prompt = PromptTemplate(template=prompt, input_variables=[&quot;question&quot;])

chat_chain = LLMChain(llm=llm, prompt=llama_chat_prompt)

chat_question = { &quot;question&quot;: &quot;What do you think are the most beautiful things in the Autumn in the U.S.?&quot;}

messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: chat_question[&apos;question&apos;]})

response = chat_chain(chat_question)

messages.append({&quot;role&quot;: &quot;Assistant&quot;, &quot;content&quot;: response[&apos;text&apos;]})</code></pre><p>The response is like:</p><pre><code class="language-py">I&apos;m here to help you with your question. However, I must inform you that the concept of &quot;beauty&quot; is subjective and can vary from person to person. What one person finds beautiful may not be the same for another.
That being said, Autumn in the U.S. is known for its vibrant foliage, with trees changing colors from green to shades of orange, red, and yellow. The most beautiful things about Autumn in the U.S. can be observed through the following:
1. Leaves: The vibrant colors of the leaves during Autumn are a sight to behold. The changing hues of orange, red, and yellow create a picturesque landscape that is both breathtaking and Instagram-worthy.
2. Fall Foliage: The term &quot;fall foliage&quot; refers to the vibrant colors of the leaves during Autumn. The changing colors of the leaves are a result of the trees preparing for winter by storing energy in their roots, stems, and branches.
3. Pumpkins: Pumpkins are a staple of Autumn in the U.S., often used in decorations</code></pre><p>This is a pretty standard response, then let&apos;s ask a follow-up question based on the response above:</p><pre><code class="language-py">prompt = create_chat_prompt(pre_prompt=pre_prompt, 
                            chat_messages=messages)
                            
llama_chat_prompt = PromptTemplate(template=prompt, input_variables=[&quot;question&quot;])

chat_chain = LLMChain(llm=llm, prompt=llama_chat_prompt)


chat_question = { &quot;question&quot;: &quot;For the 2nd point you mentioned above, can you please make a 3 day travel plan?&quot;}
messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: chat_question})

response = chat_chain(chat_question)

messages.append({&quot;role&quot;: &quot;Assistant&quot;, &quot;content&quot;: response[&apos;text&apos;]})</code></pre><p>As you can see, the question does not specify what 2nd point is, while the model is able to grasp that based on the chat history, and the response is like below:</p><pre><code class="language-py">Of course! I&apos;d be happy to help you create a 3-day travel plan for experiencing the beautiful things about Autumn in the U.S. Here is a sample itinerary:
Day 1:
* Stop 1: Take a scenic drive through the Adirondack Mountains in upstate New York. The mountains offer breathtaking views of the changing leaves, and there are many scenic overlooks and hiking trails to explore.
* Stop 2: Visit the Hudson River Valley, which is known for its picturesque towns, farms, and vineyards. Take a stroll through the charming streets of Cold Spring or Beacon, and enjoy the fall foliage along the riverfront.
Day 2:
* Stop 1: Head to New England, specifically Vermont or New Hampshire, for some of the most spectacular fall foliage in the country. Take a drive through the Green Mountains or White Mountains, and stop at scenic overlooks and hiking trails along the way.
* Stop 2: Visit the coastal towns of Maine, such as Kennebunkport or Camden</code></pre><h2 id="3-summary">3 Summary</h2><p>Some the snippets are not made into a function just for demo purposes, while you can see by adding system messages and &#xA0;chat history into the prompt, Llama 2 becomes even more intelligent and helpful. </p><p>So far, we have covered topics of Llama 2 regarding:</p><ul><li>Fast inference using GPUs</li><li>Better prompt tactics for reasonable response</li><li>Chat with Llama 2</li><li>RAG for domain knowledge question &amp; answering</li></ul><p>This means that a lot of useful apps powered by Llama 2 can be built using above tech stack. Stay tuned for more valuable sharing!</p><h2 id="reference">Reference</h2><p>How to Prompt Llama 2:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/blog/llama2?ref=localhost#how-to-prompt-llama-2"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Llama 2 is here - get it on Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="How to Prompt Correctly with Llama 2?"><span class="kg-bookmark-author">get it on Hugging Face</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://huggingface.co/blog/assets/llama2/thumbnail.jpg" alt="How to Prompt Correctly with Llama 2?"></div></a></figure><p></p>]]></content:encoded></item><item><title><![CDATA[Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs]]></title><description><![CDATA[Let Llama 2 help credit card fraud detection!
]]></description><link>https://realvincentyuan.github.io/Spacecraft/build-a-fraud-intelligence-analyst-powered-by-llama-2-in-google-colab-with-gpus/</link><guid isPermaLink="false">668a1b22ac15d470add4a2e2</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 13 Jan 2024 04:55:34 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs"><p>Last time, we introduced how to use GPUs in Google Colab to run RAG with Llama 2. Today, a practical use case is discussed - fraudulent credit card transaction detection, powered by Llama 2.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://realvincentyuan.github.io/Spacecraft/run-llama-2-with-retrieval-augmented-generation-rag-in-google-colab-with-gpus/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs</div><div class="kg-bookmark-description">Run Llama2 with RAG in Google Colab.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://realvincentyuan.github.io/Spacecraft/favicon.ico" alt="Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs"><span class="kg-bookmark-author">Spacecraft</span><span class="kg-bookmark-publisher">Vincent Yuan</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1677756119517-756a188d2d94?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDR8fGFpfGVufDB8fHx8MTcwMTYzNjU4OHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs"></div></a></figure><p>Fraud detection is a critical task for businesses of all sizes. By identifying and investigating fraudulent transactions, businesses can protect their bottom line and keep their customers safe.</p><p>Llama 2 is a large language model that can be used to generate text, translate languages, write different kinds of creative content, and more. In this post, we&apos;ll show you how to use Llama 2 to build a Fraud Intelligence Analyst that can detect fraudulent patterns of credit card transactions and answer any questions regarding the transactions.</p><p>This Fraud Intelligence Analyst can be used to help fraud detection analysts and data scientists build better solutions to the fraud detection problem. By providing insights into the data, the Fraud Intelligence Analyst can help analysts identify new patterns of fraud and develop new strategies to combat it.</p><p>This post will show:</p><ul><li>Load Llama 2 gguf model from HuggingFace</li><li>Run Llam2 2 with GPUs</li><li>Create a vector store from a CSV file that has credit card transaction data</li><li>Perform question and answering using Retrieval Augmented Generation(RAG)</li></ul><h2 id="1-dependencies">1 Dependencies</h2><p>Firstly, install Python dependencies as below:</p><pre><code class="language-py">!CMAKE_ARGS=&quot;-DLLAMA_CUBLAS=on&quot; FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir

!pip install huggingface_hub   chromadb langchain sentence-transformers pinecone_client</code></pre><p>Then import dependencies as below:</p><pre><code class="language-py">import numpy as np
from huggingface_hub import hf_hub_download
from llama_cpp import Llama

from langchain.llms import LlamaCpp
from langchain.chains import LLMChain
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate

# Vector store
from langchain.document_loaders import CSVLoader
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain.vectorstores import Chroma

# Show result
import markdown</code></pre><p>This credit card transaction dataset will be used to create the vector store:</p><pre><code class="language-py">from google.colab import drive
drive.mount(&apos;/content/drive&apos;)

source_text_file = &apos;/content/drive/MyDrive/Research/Data/GenAI/credit_card_fraud.csv&apos;</code></pre><p>The transaction data is like below:</p><!--kg-card-begin: html--><table>
<thead>
<tr>
<th style="text-align: right">transaction time</th>
<th style="text-align: right">merchant</th>
<th style="text-align: right">amt</th>
<th style="text-align: right">city_pop</th>
<th style="text-align: right">is_fraud</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: right">2019-01-01 00:00:44</td>
<td style="text-align: right">&quot;Heller, Gutmann and Zieme&quot;</td>
<td style="text-align: right">107.23</td>
<td style="text-align: right">149</td>
<td style="text-align: right">0</td>
</tr>
<tr>
<td style="text-align: right">2019-01-01 00:00:51</td>
<td style="text-align: right">Lind-Buckridge</td>
<td style="text-align: right">220.11</td>
<td style="text-align: right">4154</td>
<td style="text-align: right">0</td>
</tr>
<tr>
<td style="text-align: right">2019-01-01 00:07:27</td>
<td style="text-align: right">Kiehn Inc</td>
<td style="text-align: right">96.29</td>
<td style="text-align: right">589</td>
<td style="text-align: right">0</td>
</tr>
<tr>
<td style="text-align: right">2019-01-01 00:09:03</td>
<td style="text-align: right">Beier-Hyatt</td>
<td style="text-align: right">7.77</td>
<td style="text-align: right">899</td>
<td style="text-align: right">0</td>
</tr>
<tr>
<td style="text-align: right">2019-01-01 00:21:32</td>
<td style="text-align: right">Bruen-Yost</td>
<td style="text-align: right">6.85</td>
<td style="text-align: right">471</td>
<td style="text-align: right">1</td>
</tr>
</tbody>
</table><!--kg-card-end: html--><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">The public fraud credit card transaction data can be found here: https://www.datacamp.com/workspace/datasets/dataset-python-credit-card-fraud</div></div><h2 id="2-load-llama-2-from-huggingface">2 Load Llama 2 from HuggingFace</h2><p>Firstly create a callback manager for the streaming output of text, and specify the model names in the HuggingFace:</p><pre><code class="language-py"># for token-wise streaming so you&apos;ll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])

# Download the model
!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf</code></pre><p>Then specify the model path to be loaded into <code>LlamaCpp</code>:</p><pre><code class="language-py">model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;</code></pre><p>Specify the GPU settings:</p><pre><code class="language-py">n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.</code></pre><p>Next, let&apos;s load the model using <code>langchain</code> as below:</p><pre><code class="language-py">from langchain.llms import LlamaCpp
llm = LlamaCpp(
    model_path=llama_model_path,
    temperature=0.0,
    top_p=1,
    n_ctx=16000,
    n_gpu_layers=n_gpu_layers,
    n_batch=n_batch,
    callback_manager=callback_manager,
    verbose=True,
)</code></pre><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Be sure to set up <code>n_gpu_layers</code> and <code>n_batch</code>, it shows <code>BLAS = 1</code> in the output if it is set up correctly.</div></div><h2 id="3-question-answering">3 Question Answering</h2><p>This time the CSV loader is used to embed a table and create a vector database, then the LLama 2 model will answer questions based on that file.</p><h3 id="31-create-a-vector-store">3.1 Create a Vector Store</h3><p>Firstly let&apos;s load the CSV data from Colab:</p><pre><code class="language-py">embedding_function = SentenceTransformerEmbeddings(model_name=&quot;all-MiniLM-L6-v2&quot;)

loader = CSVLoader(source_text_file, encoding=&quot;windows-1252&quot;)
documents = loader.load()

# Create a vector store
db = Chroma.from_documents(documents, embedding_function)</code></pre><h3 id="32-rag">3.2 RAG</h3><p>We then use <code>RetrievalQA</code> to retrieve the documents from the vector database and give the model more context on Llama 2, thereby increasing its knowledge.</p><pre><code class="language-py"># use another LangChain&apos;s chain, RetrievalQA, to associate Llama with the loaded documents stored in the vector db
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm,
    retriever=vstore.as_retriever(search_kwargs={&quot;k&quot;: 1})
)</code></pre><p>Then the model is ready for your questions:</p><pre><code class="language-py">question = &quot;Do you see any common patter for those fraudulent transactions? think about this step by step and provide examples for each pattern that you found.&quot;
result = qa_chain({&quot;query&quot;: question})
print(markdown.markdown(result[&apos;result&apos;]))
</code></pre><p>The response is like: </p><pre><code class="language-py">Yes, I can identify some common patterns in the provided data for fraudulent transactions. Here are some examples of each pattern I found:

1. Recurring Transactions: There are several recurring transactions in the dataset, such as those with the same date and time every day or week. For example, transaction #86cad0e7682a85fa6418dde1a0a33a44 has a recurrence pattern of every Monday at 5:50 AM. While this alone does not necessarily indicate fraud, it could be a sign of automated or scripted transactions.

2. High-Value Transactions: Some transactions have unusually high values compared to the average transaction amount for the merchant and category. For example, transaction #86cad0e7682a85fa6418dde1a0a33a44 has an amt of $32.6, which is significantly higher than the average transaction amount for gas transport merchants in Browning, MO ($19.2). This could indicate a fraudulent transaction.

3. Multiple Transactions from Same IP Address:&lt;p&gt;Yes, I can identify some common patterns in the provided data for fraudulent transactions. </code></pre><h2 id="4-conclusion">4 Conclusion</h2><p>In fraud detection, case studies are a common and important part of the process. However, they can be labor-intensive to create. Llama 2 and RAG can help to automate this process, making it more efficient and effective.</p><p>Llama 2 and RAG can be used to generate case studies that are tailored to specific questions or scenarios. This can help fraud detection analysts to identify patterns and trends that they might not otherwise have seen. Additionally, the case studies can be used to train new analysts on the latest fraud detection techniques.</p><p>Llama 2 and RAG are still in development, but they have the potential to revolutionize the way that fraud detection case study is conducted. By making it easier to create and analyze case studies, these tools can help fraud detection analysts to stay ahead of the curve.</p><p>Stay tuned for more applications like this one!</p><h2 id="reference">Reference</h2><p>Langchain - llama.cpp:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://python.langchain.com/docs/integrations/llms/llamacpp?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Llama.cpp | &#x1F99C;&#xFE0F;&#x1F517; Langchain</div><div class="kg-bookmark-description">llama-cpp-python is a</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://python.langchain.com/img/favicon.ico" alt="Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs"><span class="kg-bookmark-author">&#x1F99C;&#xFE0F;&#x1F517; LangChain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://python.langchain.com/img/parrot-chainlink-icon.png" alt="Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs"></div></a></figure><p>Create a vector store using CSV files:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://how.wtf/how-to-use-csv-files-in-vector-stores-with-langchain.html?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">How to use CSV files in vector stores with Langchain</div><div class="kg-bookmark-description">A guide for using CSV files in vector stores with langchain</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://how.wtf/images/favicon.ico" alt="Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs"><span class="kg-bookmark-author">how.wtf</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://how.wtf/images/yjbsz4.webp" alt="Build a Fraud Intelligence Analyst Powered by Llama 2 in Google Colab with GPUs"></div></a></figure><p></p>]]></content:encoded></item><item><title><![CDATA[Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs]]></title><description><![CDATA[Run Llama 2 with RAG in Google Colab.
]]></description><link>https://realvincentyuan.github.io/Spacecraft/run-llama-2-with-retrieval-augmented-generation-rag-in-google-colab-with-gpus/</link><guid isPermaLink="false">668a1b22ac15d470add4a2e1</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 07 Jan 2024 21:53:28 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs"><p>Utilizing GenAI models on Colab with its free GPUs proves advantageous for GenAI developers. It enables faster execution compared to personal computers lacking powerful GPUs, thereby allowing the testing of more ideas within the same timeframe.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/colab_gpu.png" class="kg-image" alt="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs" loading="lazy"><figcaption>Colab GPU</figcaption></figure><p>This post will show you how you can:</p><ul><li>Load Llama 2 gguf model from HuggingFace</li><li>Run Llam2 2 with GPUs</li><li>Create a vector store using Pinecone</li><li>Perform question and answering using Retrieval Augmented Generation(RAG)</li></ul><h2 id="1-dependencies">1 Dependencies</h2><p>Firstly, install Python dependencies as below:</p><pre><code class="language-py">!CMAKE_ARGS=&quot;-DLLAMA_CUBLAS=on&quot; FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir

!pip install huggingface_hub   chromadb langchain sentence-transformers pinecone_client</code></pre><p>Then import dependencies as below:</p><pre><code class="language-py">import numpy as np
from huggingface_hub import hf_hub_download
from llama_cpp import Llama

from langchain.llms import LlamaCpp
from langchain.chains import LLMChain
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate</code></pre><p>Then mount the Google Drive to load the <code>NBA player sample data</code> shared by Meta in the <a href="https://github.com/facebookresearch/llama-recipes/blob/main/demo_apps/nba.txt?ref=localhost">llama-recipes repo</a>. This dataset will be used to create the vector store:</p><pre><code class="language-py">from google.colab import drive
drive.mount(&apos;/content/drive&apos;)

source_text_file = &apos;/content/drive/MyDrive/Research/Data/GenAI/nba.txt&apos;</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/202401071542642.png" class="kg-image" alt="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs" loading="lazy"><figcaption>NBA Player Sample Data</figcaption></figure><h2 id="2-load-llama-2-from-huggingface">2 Load Llama 2 from HuggingFace</h2><p>Firstly create a callback manager for the streaming output of text, and specify the model names in the HuggingFace:</p><pre><code class="language-py"># for token-wise streaming so you&apos;ll see the answer gets generated token by token when Llama is answering your question
callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])

# Download the model
!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q5_0.gguf</code></pre><p>Then specify the model path to be loaded into <code>LlamaCpp</code>:</p><pre><code class="language-py">model_path = &apos;llama-2-7b-chat.Q5_0.gguf&apos;</code></pre><p>Specify the GPU settings:</p><pre><code class="language-py">n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.
n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.</code></pre><p>Next, let&apos;s load the model using <code>langchain</code> as below:</p><pre><code class="language-py">from langchain.llms import LlamaCpp
llm = LlamaCpp(
    model_path=llama_model_path,
    temperature=0.0,
    top_p=1,
    n_ctx=16000,
    n_gpu_layers=n_gpu_layers,
    n_batch=n_batch,
    callback_manager=callback_manager,
    verbose=True,
)</code></pre><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Be sure to set up <code>n_gpu_layers</code> and <code>n_batch</code>, it shows <code>BLAS = 1</code> in the output if it is set up correctly.</div></div><h2 id="3-rag">3 RAG</h2><p>Retrieval Augmented Generation (RAG) is important because it addresses key limitations of large language models (LLMs). Here&apos;s why:</p><ul><li><strong>Factual Accuracy:</strong> LLMs can be creative and articulate, but they aren&apos;t always truthful. RAG integrates external knowledge sources, ensuring generated responses are grounded in real facts.</li><li><strong>Reduced Hallucinations:</strong> LLMs can sometimes invent information or make false claims. RAG combats hallucinations by providing LLMs with reliable context from external sources.</li><li><strong>Domain Expertise:</strong> LLMs struggle with specialized topics. RAG allows them access to specific knowledge bases, like medical journals or legal documents, enhancing their responses in niche areas.</li><li><strong>Transparency and Trust:</strong> RAG systems can show their work! Users can see the sources used to generate responses, building trust and enabling fact-checking.</li></ul><p>In short, RAG makes LLMs more reliable, accurate, and versatile, opening doors for their use in areas like education, legal advice, and scientific research. It&apos;s a crucial step towards trustworthy and grounded AI.</p><h3 id="31-%08initialize-pinecone">3.1 Initialize Pinecone</h3><p>Let&apos;s import a few related packages and initialize Pinecone - a vector store provider.</p><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Quick start for Pinecone setup: https://docs.pinecone.io/docs/quickstart</div></div><pre><code class="language-py">from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma

from langchain.embeddings import HuggingFaceEmbeddings</code></pre><p>Get your Pinecone API key and env here:</p><pre><code class="language-py">PINECONE_API_KEY = &apos;&apos;
PINECONE_ENV = &apos;&apos;</code></pre><p>And initialize it:</p><pre><code class="language-py">import pinecone
from langchain.vectorstores import Pinecone

# Initialize Pinecone
pinecone.init(
    api_key=PINECONE_API_KEY,  
    environment=PINECONE_ENV  
)

pinecone_index_nm = &apos;qabot&apos;</code></pre><h3 id="32-create-a-vector-store">3.2 Create a Vector Store</h3><p>Firstly let&apos;s load the data from Colab:</p><pre><code class="language-py">embeddings = HuggingFaceEmbeddings()

# Load the document, split it into chunks, embed each chunk and load it into the vector store.
raw_documents = TextLoader(source_text_file).load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)</code></pre><p>Then create the vector store:</p><pre><code class="language-py"># Send embedding vectors to Pinecone with Langchain

vstore = Pinecone.from_documents(documents, embeddings, index_name=pinecone_index_nm)</code></pre><h3 id="33-rag">3.3 RAG</h3><p>We then use <code>RetrievalQA</code> to retrieve the documents from the vector database and give the model more context on Llama 2, thereby increasing its knowledge.</p><pre><code class="language-py"># use another LangChain&apos;s chain, RetrievalQA, to associate Llama with the loaded documents stored in the vector db
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm,
    retriever=vstore.as_retriever(search_kwargs={&quot;k&quot;: 1})
)</code></pre><p>Then the model is ready for your questions:</p><pre><code class="language-py">question = &quot;Who is the tallest in Atlanta Hawks&quot;
result = qa_chain({&quot;query&quot;: question})</code></pre><p>The response is like: </p><pre><code class="language-py">{&apos;query&apos;: &apos;Who is the tallest in Atlanta Hawks&apos;,
 &apos;result&apos;: &apos; The tallest player on the Atlanta Hawks roster is Saddiq Bey at 6\&apos;7&quot;.&apos;}</code></pre><h2 id="4-conclusion">4 Conclusion</h2><p>Utilizing the open-source Llama 2 model with RAG, you can create a robust chatbot tailored to your domain knowledge. This capability proves highly beneficial for enterprise users, as it circumvents privacy concerns and data leaks, ensuring everything operates in-house in theory.</p><p>However, there&apos;s still more to uncover in our quest to construct a secure and responsible GenAI app at the enterprise level. Stay tuned for further updates.</p><h2 id="reference">Reference</h2><p>Langchain - llama.cpp:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://python.langchain.com/docs/integrations/llms/llamacpp?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Llama.cpp | &#x1F99C;&#xFE0F;&#x1F517; Langchain</div><div class="kg-bookmark-description">llama-cpp-python is a</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://python.langchain.com/img/favicon.ico" alt="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs"><span class="kg-bookmark-author">&#x1F99C;&#xFE0F;&#x1F517; LangChain</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://python.langchain.com/img/parrot-chainlink-icon.png" alt="Run Llama 2 with Retrieval Augmented Generation in Google Colab with GPUs"></div></a></figure>]]></content:encoded></item><item><title><![CDATA[Say Hello to 2024]]></title><description><![CDATA[Reflecting on 2023 and looking ahead to 2024.]]></description><link>https://realvincentyuan.github.io/Spacecraft/say-hello-to-2024/</link><guid isPermaLink="false">668a1b22ac15d470add4a2e0</guid><category><![CDATA[Pro]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 31 Dec 2023 20:51:10 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1694140067948-0a015a055ce3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE2fHx2eTEyMTh8ZW58MHx8fHwxNzA0MDM5OTA0fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1694140067948-0a015a055ce3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE2fHx2eTEyMTh8ZW58MHx8fHwxNzA0MDM5OTA0fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Say Hello to 2024"><p>As we near the conclusion of 2023, I find myself eager to reflect on the year and gather my thoughts for the upcoming year, 2024. This past year has been incredibly fruitful and meaningful, prompting me to consider my plans and aspirations for the future in this post.</p><h2 id="1-things-accomplished">1 Things Accomplished</h2><p>The theme for 2023 revolves around <code>stepping out of one&apos;s comfort zone</code>! Here&apos;s a glimpse into my endeavors:</p><ul><li>Relocated to the U.S. and established a new life.</li><li>Spearheaded a sophisticated project for my company.</li><li>Rekindled my passion for tennis, making remarkable advancements.</li><li>Crafted <code>SpaceCraft</code> (the blog) from the ground up.</li><li>Explored numerous destinations across the U.S. and captured stunning moments through photography.</li></ul><p>Shall we delve deeper into each of these experiences?</p><h3 id="11-migration-to-the-us">1.1 Migration to the U.S.</h3><p>Making the decision to leave my entire family, including my 18-month-old daughter, behind in pursuit of a better life in the U.S. was an arduous choice for a 30-year-old man like myself. My aim is to advance my career prospects, ensure a secure future for my family, and offer enhanced educational opportunities for my daughter.</p><p>The day it actually happened marked one of the most challenging moments for all of us as a family, bidding farewell at Shanghai Airport. Uncertainty clouded my mind&#x2014;I couldn&apos;t fathom when I might reunite with them. I found myself alone in a country thousands of miles away from home, with the responsibility to establish a life on my own.</p><p>Upon arriving in the U.S., the challenges multiplied. Everything seemed different&#x2014;I struggled to open a bank account, acquire a social security number, and even rent a car. Simple tasks like shopping for groceries became a puzzle as I navigated unfamiliar stores. Loneliness loomed large, especially during nights and weekends, making the initial period here deeply unsettling.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/the-sun-is-setting-over-a-body-of-water-LYHn-7guQfE" class="kg-image" alt="Say Hello to 2024" loading="lazy"><figcaption>Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>However, I persevered by adhering to my goals, enabling me to realign both my work and personal life swiftly. As I honed my focus, I gradually embraced the lifestyle here through adaptation and learning. It&apos;s crucial to prioritize life goals, exhibit resilience, and persist despite distractions. This approach significantly impacts your long-term journey, making a substantial difference.</p><h3 id="12-progress-in-work">1.2 Progress in Work</h3><p>Since arriving in the U.S., my primary focus at work has been credit card application fraud detection, employing a combination of knowledge graph and machine learning techniques. This project stands out as one of the most intricate endeavors I&apos;ve undertaken, encompassing both technical complexities and strategic business considerations. Leveraging insights from previous experiences was instrumental in its success, and I&apos;ve predominantly shared these insights within the Tech section of this blog, using publicly available datasets.</p><h3 id="13-polished-tennis-skills">1.3 Polished Tennis Skills</h3><p>Playing tennis can evoke a complex array of emotions, particularly when the game proves challenging to grasp. In such instances, the experience can be far from enjoyable. Picture yourself repeatedly collecting tennis balls under scorching temperatures exceeding 35&#xB0;C (95&#xB0;F) for 2 to 3 hours due to an inability to sustain a rally with opponents at the outset.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/IMG_8688.jpeg" class="kg-image" alt="Say Hello to 2024" loading="lazy"><figcaption>Practice of Tennis, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Tennis ceased to be just a recreational activity; it evolved into a pursuit that toughened me. Throughout summers, I devoted numerous nights and weekends to honing my serving and striking skills against a wall, armed only with a bottle of water and a tree brimming with tennis balls cascading out of the court. It marked the initial occasion I approached a sport with such earnestness and committed myself to extensive practice, determined to master it regardless of the challenges. </p><p>While I may not yet classify myself as an intermediate amateur player, significant progress has undeniably been achieved. Now, I derive more enjoyment from the game than the frustration it once caused me.</p><h3 id="14-developed-spacecraft">1.4 Developed SpaceCraft</h3><p>I deliberated extensively before deciding whether to relaunch my blog and determining its content and style. Fortunately, I reached a conclusion from an objective viewpoint: just write if I enjoy it, keeping it that simple!</p><p>I consider myself fortunate not to have tainted it by viewing it solely as a means for making money, as this would significantly impact the content I share. Therefore, I approach it as a platform to chronicle my life and impart something meaningful to the world&#x2014;nothing more!</p><p>For insights into the technical aspects of constructing this blog, please refer to the series below:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://realvincentyuan.github.io/Spacecraft/host-a-ghost-blog-on-aws-in-2023-part-4-create-a-great-table-of-contents/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Host a Ghost Blog on AWS in 2023 (IV) - Create a Functional Table of Contents</div><div class="kg-bookmark-description">Table of contents is easy for users to navigate through the long article, but Ghost did not provide a nice out-of-the-box solution.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://realvincentyuan.github.io/Spacecraft/favicon.ico" alt="Say Hello to 2024"><span class="kg-bookmark-author">Spacecraft</span><span class="kg-bookmark-publisher">Vincent Yuan</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1691973171931-b095945dc8e8?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDExfHx2eTEyMTh8ZW58MHx8fHwxNjkyNDcwMDkwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Say Hello to 2024"></div></a></figure><h3 id="15-traveling-and-learning">1.5 Traveling and Learning</h3><p>Traveling has significantly enriched my life in the U.S. I&apos;ve gained extensive knowledge about this country and captured numerous wonderful photos along the way. It brings me immense joy to know that many of my friends thoroughly enjoy the posts in the <code>Life</code> section of my blog and admire my photography.</p><p>Since February 2023, I&apos;ve curated and uploaded 863 photos to my portfolio on Unsplash. Remarkably, these images have garnered an average of 200,000 views and 1,000 downloads per month.</p><p>Photography is a passion of mine, and I find genuine happiness in knowing that my work resonates with people worldwide.</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://unsplash.com/@vincentyuan87?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Vincent Yuan @USA (@vincentyuan87) | Unsplash Photo Community</div><div class="kg-bookmark-description">See 863 of the best free to download photos, images, and wallpapers by Vincent Yuan @USA on Unsplash.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://unsplash.com/apple-touch-icon.png" alt="Say Hello to 2024"><span class="kg-bookmark-author">Unsplash</span><span class="kg-bookmark-publisher">Unsplash</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/opengraph/1x1.png?blend=https%3A%2F%2Fimages.unsplash.com%2Fopengraph%2F1x1.png%3Fblend%3Dhttps%253A%252F%252Fimages.unsplash.com%252Fphoto-1703694295485-f4e100a1e095%253Fblend%253Dhttps%25253A%25252F%25252Fimages.unsplash.com%25252Fprofile-1690083739696-31af24f41924image%25253Fcrop%25253Dfaces%252526fm%25253Dpng%252526h%25253D160%252526mask%25253Dellipse%252526w%25253D160%252526auto%25253Dformat%252526fit%25253Dcrop%252526q%25253D60%252526ixlib%25253Drb-4.0.3%2526blend-mode%253Dnormal%2526blend-y%253D190%2526crop%253Dfaces%25252Cedges%2526h%253D630%2526w%253D1200%2526auto%253Dformat%2526fit%253Dcrop%2526q%253D60%2526ixid%253DM3wxMjA3fDB8MXxhbGx8MXx8fHx8fDJ8fDE3MDQwNTQzNTZ8%2526ixlib%253Drb-4.0.3%26fm%3Dpng%26h%3D630%26txt%3DVincent%2BYuan%2B%2540USA%26txt-align%3Dcenter%26txt-color%3Dfff%26txt-font%3DHelveticaNeue-Bold%26txt-size%3D64%26txt-y%3D400%26w%3D1200%26auto%3Dformat%26fit%3Dcrop%26q%3D60&amp;blend-w=1&amp;h=630&amp;mark=https%3A%2F%2Fimages.unsplash.com%2Fopengraph%2Flogo.png&amp;mark-align=top%2Cleft&amp;mark-pad=50&amp;mark-w=64&amp;w=1200&amp;auto=format&amp;fit=crop&amp;q=60" alt="Say Hello to 2024"></div></a></figure><h2 id="2-looking-ahead-to-2024">2 Looking Ahead to 2024</h2><p>I believe I&apos;m headed in the right direction, with no significant changes needed. However, I plan to dedicate more time to integrating generative AI into my workflow as I see this as a crucial factor for the long-term development of my career. I&apos;ll be sharing more posts on this topic later when the timing is right.</p><p>In addition to work, I&apos;ll be allocating most of my time to the following:</p><ul><li>Investment</li><li>Photography</li><li>Tennis</li></ul><p>I&apos;ll also be exploring these subjects for potential posts in either the <code>Pro</code> or <code>Life</code> columns. Stay tuned for more!</p>]]></content:encoded></item><item><title><![CDATA[Highlights of the Trip to the East Coast of the United States]]></title><description><![CDATA[A completely different experience of the life in the East Coast of the United States.]]></description><link>https://realvincentyuan.github.io/Spacecraft/highlights-of-the-trip-to-east-coast-america/</link><guid isPermaLink="false">668a1b22ac15d470add4a2df</guid><category><![CDATA[Life]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 31 Dec 2023 05:14:02 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703641853572-2466192f933a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQyMXx8dnkxMjE4fGVufDB8fHx8MTcwMzk5MjQ4NHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703641853572-2466192f933a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQyMXx8dnkxMjE4fGVufDB8fHx8MTcwMzk5MjQ4NHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Highlights of the Trip to the East Coast of the United States"><p>It&apos;s been some time since my last trip, and this time, I embarked on a 7-day adventure spanning Washington D.C., Delaware, Philadelphia (Philly), and New York. Equipped with my new camera, the Canon EOS R8 paired with a 24-105mm lens, purchased during the Black Friday season, I seized the opportunity to capture numerous breathtaking vistas during the entirety of my journey.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/east_coast_route.png" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Route</figcaption></figure><h2 id="1-washington-dc">1 Washington D.C.</h2><p>Washington, D.C., the capital of the United States, is known for several prominent aspects:</p><ul><li><code>Monuments and Memorials</code><strong>:</strong> It&apos;s famous for its iconic landmarks like the Washington Monument, Lincoln Memorial, Jefferson Memorial, and the Martin Luther King Jr. Memorial, which honor key figures and pivotal moments in American history.</li><li><code>Government Buildings</code><strong>:</strong> Washington, D.C. is home to the White House (the residence of the U.S. President), the U.S. Capitol (where Congress meets), the Supreme Court, and various federal agencies, making it the political center of the country.</li><li><code>Museums and Cultural Institutions</code><strong>:</strong> The city hosts numerous world-class museums and galleries, including the Smithsonian Institution, comprising multiple museums such as the National Air and Space Museum, National Museum of American History, National Museum of Natural History, and many others, showcasing art, history, culture, and scientific achievements.</li><li><code>Cherry Blossom Festival</code><strong>:</strong> Each spring, the city&apos;s cherry blossom trees bloom, drawing millions of visitors to the National Mall. The National Cherry Blossom Festival celebrates this natural beauty and includes various events and activities.</li><li><code>Cultural Diversity</code><strong>:</strong> Washington, D.C. is a diverse city with a rich cultural tapestry, reflected in its neighborhoods, cuisine, festivals, and events. It&apos;s a melting pot of different cultures, languages, and traditions.</li><li><code>Education and Research</code><strong>:</strong> The city hosts several renowned universities, think tanks, and research institutions, including Georgetown University, George Washington University, and the Brookings Institution, contributing to its intellectual vibrancy.</li><li><code>Historic Neighborhoods</code><strong>:</strong> Areas like Georgetown, Capitol Hill, and Dupont Circle offer historic charm, cobblestone streets, unique architecture, and a blend of residential, commercial, and cultural spaces.</li><li><code>Political Activism and Protests</code><strong>:</strong> Being the seat of the U.S. government, Washington, D.C. often serves as a focal point for political activism, demonstrations, and protests on various national and international issues.</li><li><code>Sports and Entertainment</code><strong>:</strong> The city has professional sports teams like the Washington Football Team (NFL), Washington Nationals (MLB), Washington Wizards (NBA), and Capitals (NHL), along with a vibrant entertainment scene with theaters, live music venues, and restaurants.</li><li><code>International Influence</code><strong>:</strong> As the capital of the United States, Washington, D.C. plays a significant role in international diplomacy, hosting embassies, international organizations, and summits that shape global policies.</li></ul><p>These elements collectively contribute to the distinctiveness and significance of Washington, D.C. in the United States and worldwide.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://source.unsplash.com/a-body-of-water-with-a-tower-in-the-background-1uSarVDyVZQ" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Washington Monument, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>The grand government buildings here stand out from those in other cities. They exude a sense of decency, cleanliness, and seamlessly blend in with the rest of the city&apos;s architecture.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/a-large-building-with-a-christmas-tree-in-front-of-it-XDN66RyYtwI" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>United States Capitol, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>During the Christmas season, the city transforms with an abundance of Christmas trees and dazzling lights. This festive setup adds a welcoming and cozy vibe to the cityscape, making it more accessible and warm compared to other times of the year.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/a-decorated-christmas-tree-in-a-large-building-Q9n9YAMRLpE" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Library of Congress, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Georgetown stands apart from downtown D.C. with its unique charm. Here, you&apos;ll find quaint yet elegant buildings that create a different vibe. The streets are brimming with charming shops, offering a delightful experience. It&apos;s the perfect spot to savor local seafood, coffee, and pastries.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/a-city-street-filled-with-lots-of-traffic-at-night-GlhHqBMsWyY" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Georgetown, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Please be aware that most museums in D.C. offer free admission, providing ample opportunities to explore and learn. They are fantastic places to discover and expand your knowledge.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/7NABEgW4XVE" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Smithsonian National Museum of Natural History, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h2 id="2-delaware">2 Delaware</h2><p>We dedicated a day to Delaware, not so much for its tourist spots, but for its remarkable sales tax-free advantage. Outlets Delaware stands out as an excellent shopping destination when in the state.</p><p>While we cherished the picturesque views of the Atlantic Ocean near Rehoboth Beach, Delaware.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/a-view-of-the-ocean-from-the-beach-VWAcc5vJuXs" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Rehoboth Beach, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>The water alongside the beach shimmered with vibrant hues from the afternoon sunlight, creating a picturesque scene. It was an ideal spot for a leisurely walk and relaxation, offering a clean and tranquil ambiance.</p><h2 id="3-philadelphia">3 Philadelphia</h2><p>This was where I learned a significant part of American history because Philadelphia witnessed several crucial historical events. For instance, at Liberty Hall, the Declaration of Independence was crafted on August 2, 1776.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/a-couple-of-people-standing-in-front-of-a-building-l2p3svYeXb0" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Independence Hall, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>At the Independence Hall tour, knowledgeable rangers guide you through crucial historical events along the timeline. This immersive experience allows you to vividly sense the significant, destiny-altering moments of the United States.</p><p>Moreover, if you haven&apos;t tried it yet, don&apos;t miss the chance to savor a Philly cheese steak&#x2014;it&apos;s truly something special!</p><h2 id="4-new-york">4 New York</h2><p>New York City offers an abundance of attractions and experiences and it is the most dynamic cities in the east coast in my eyes.</p><h3 id="41-museums">4.1 Museums</h3><ul><li><code>The Metropolitan Museum of Art (The Met)</code><strong>:</strong> One of the world&apos;s largest and most comprehensive art museums, housing an extensive collection spanning various cultures and time periods.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/rgMjyZzLEvs" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>The Met, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><ul><li><code>Museum of Modern Art (MoMA)</code><strong>:</strong> Known for its impressive collection of modern and contemporary art, including works by Picasso, Van Gogh, and Warhol.</li><li><code>American Museum of Natural History</code><strong>:</strong> Features fascinating exhibits on natural history, including dinosaur fossils, animal dioramas, and a planetarium.</li><li><code>The Guggenheim Museum</code><strong>:</strong> Known for its unique architecture designed by Frank Lloyd Wright and its collection of modern and contemporary art.</li><li><code>The Whitney Museum of American Art</code><strong>:</strong> Showcases a vast collection of American contemporary art, including works by renowned artists.</li></ul><h3 id="42-scenery">4.2 Scenery</h3><ul><li><code>Central Park</code>: A vast green oasis in the heart of Manhattan offering scenic walking paths, lakes, meadows, and recreational activities like boating, biking, and picnicking.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://source.unsplash.com/O8w88ycsbto" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Bethesda Terrace, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><ul><li><code>The High Line</code>: A unique elevated park built on a former railway line, offering stunning views of the cityscape, art installations, gardens, and seating areas.</li><li><code>Brooklyn Bridge</code>: An iconic suspension bridge offering beautiful views of the Manhattan skyline and the East River, perfect for walking or cycling across.</li></ul><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://source.unsplash.com/CzIwghZv7Y0" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Brooklyn Bridge, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><ul><li><code>Top of the Rock and Empire State Building</code>: Observation decks providing panoramic views of the city from above.</li></ul><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://source.unsplash.com/-wX7Myo5Dfc" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Top of the Rock, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><ul><li><code>Statue of Liberty and Ellis Island</code>: Visit these historic landmarks to learn about immigration history and enjoy views of the New York Harbor.</li></ul><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://source.unsplash.com/RG_UoBKkt-s" class="kg-image" alt="Highlights of the Trip to the East Coast of the United States" loading="lazy"><figcaption>Statue of Liberty, Photo by <a href="https://unsplash.com/@vincentyuan87?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Vincent Yuan @USA</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h3 id="43-food">4.3 Food</h3><ul><li><code>Diverse Cuisine</code>: New York City offers a vast array of cuisines from around the world. Enjoy everything from Michelin-starred restaurants to food trucks and local delis.</li><li><code>Pizza</code>: Grab a slice of New York-style pizza from iconic spots like Joe&apos;s Pizza, Di Fara Pizza, or Lombardi&apos;s.</li><li><code>Bagels</code>: Sample authentic New York bagels from places like Russ &amp; Daughters, Ess-a-Bagel, or Absolute Bagels.</li><li><code>Food Markets</code>: Visit food markets like Chelsea Market or Smorgasburg to indulge in a variety of local and international food vendors.</li><li><code>Fine Dining</code>: Explore acclaimed restaurants offering diverse culinary experiences, from high-end steak houses to innovative fine dining establishments.</li></ul><p>New York City&apos;s diverse cultural offerings, breathtaking scenery, and vibrant culinary scene ensure there&apos;s something enjoyable for every visitor. We have spent 3 days in New York City and it was not nearly enough to enjoy this amazing city.</p><h2 id="5-remarks">5 Remarks</h2><p>On the East Coast, while you may not encounter as many stunning natural landscapes within the renowned national parks, the diverse blend of culture, architecture, museums, and culinary delights offers a unique experience unlike other parts of America. </p><p>Such a trip serves as a refreshing escape, ideal for unwinding after a year of hard work. It&apos;s a wonderful way to conclude 2023. Until 2024&#x2014;Happy New Year!</p><p></p><p> </p>]]></content:encoded></item><item><title><![CDATA[Build a Web-based GPT Chatbot with Custom Knowledge]]></title><description><![CDATA[Intelligent web chatbot powered by GPT, which knows your own data.]]></description><link>https://realvincentyuan.github.io/Spacecraft/build-a-gpt-chatbot/</link><guid isPermaLink="false">668a1b22ac15d470add4a2de</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Wed, 13 Dec 2023 04:01:57 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Build a Web-based GPT Chatbot with Custom Knowledge"><p>The advancement of generative AI is remarkable. Now, with approximately 70 lines of Python code predominantly leveraging OpenAI GPT, llama-index, and Streamlit, you can craft chatbots infused with your specialized domain knowledge. This enables the creation of a personalized assistant tailored specifically for your needs. </p><p>This post is going to share how you can build your own powerful Chatbot for your own data!</p><figure class="kg-card kg-embed-card"><iframe width="200" height="150" src="https://www.youtube.com/embed/7XGzjxJygyk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen title="Build a Web-based ChatBot with Custom Knowledge, Powered by GPT"></iframe></figure><h2 id="1-dependency">1 Dependency</h2><p>A few Python packages are needed for this app:</p><pre><code class="language-py">pip install streamlit openai llama-index nltk</code></pre><p>Also, please get an OpenAI API key by following this guide:</p><ul><li>Go to <a href="https://platform.openai.com/account/api-keys?ref=blog.streamlit.io">https://platform.openai.com/account/api-keys</a>.</li><li>Click on the <code>+ Create new secret key</code> button.</li><li>Enter an identifier name (optional) and click on the <code>Create secret key</code> button.</li><li>Copy the API key to be used in this tutorial (the key shown below was already revoked).</li></ul><h2 id="2-create-the-chatbot">2 Create the Chatbot</h2><p>The project folder can be set up like this:</p><figure class="kg-card kg-code-card"><pre><code class="language-py">chatbot
| |_main.py
| |_data
| |_.streamlit
| 	|_secrets.toml</code></pre><figcaption>File Tree</figcaption></figure><p>These files are:</p><ul><li>a <code>main.py</code> to store the code of the app.</li><li>a <code>data</code> folder that stores the input data.</li><li><code>secrets.toml</code> in the <code>.streamlit</code> folder that has the Open AI API key, like openai_key = &apos;Your OpenAI API key&apos; </li></ul><p>The <code>main.py</code> looks like this, this is all that it needs to pull up the chatbot:</p><figure class="kg-card kg-code-card"><pre><code class="language-py">import streamlit as st
from llama_index import VectorStoreIndex, ServiceContext, Document
from llama_index.llms import OpenAI
import openai
from llama_index import SimpleDirectoryReader

st.set_page_config(page_title=&quot;Chat with the Streamlit docs, powered by LlamaIndex&quot;, page_icon=&quot;&#x1F999;&quot;, layout=&quot;centered&quot;, initial_sidebar_state=&quot;auto&quot;, menu_items=None)
openai.api_key = st.secrets.openai_key
st.title(&quot;Chat with the domain knowledge, powered by LlamaIndex &#x1F4AC;&#x1F999;&quot;)
st.info(&quot;Check out the full tutorial to build this app in our [blog post](https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/)&quot;, icon=&quot;&#x1F4C3;&quot;)
         
if &quot;messages&quot; not in st.session_state.keys(): # Initialize the chat messages history
    st.session_state.messages = [
        {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Ask me a question about the fils you uploaded just now!&quot;}
    ]

# Utilities functions    
def save_uploadedfile(uploadedfile):
    import os
    
    with open(os.path.join(&quot;data&quot;,uploadedfile.name),&quot;wb&quot;) as f:
         f.write(uploadedfile.getbuffer())
            
    return st.success(f&quot;File saved to data folder!&quot; )    
    
    
@st.cache_resource(show_spinner=False)
def load_data():
    with st.spinner(text=&quot;Loading and indexing the Streamlit docs &#x2013; hang tight! This should take 1-2 minutes.&quot;):
        reader = SimpleDirectoryReader(input_dir=&quot;./data&quot;, recursive=True)
        docs = reader.load_data()
        service_context = ServiceContext.from_defaults(llm=OpenAI(model=&quot;gpt-3.5-turbo&quot;, temperature=0.5, system_prompt=&quot;You are an expert on the fraud detection and your job is to answer technical questions. Assume that all questions are related to the credit card fraud detection. Keep your answers technical and based on facts &#x2013; do not hallucinate features.&quot;))
        index = VectorStoreIndex.from_documents(docs, service_context=service_context)
        return index

    
    
# Main app

datafile = st.file_uploader(&quot;Upload your data (string only)&quot;,type=[&apos;str&apos;,&apos;csv&apos;,&apos;txt&apos;])

if datafile is not None:

    save_uploadedfile(datafile)


    index = load_data()

    if &quot;chat_engine&quot; not in st.session_state.keys(): # Initialize the chat engine
            st.session_state.chat_engine = index.as_chat_engine(chat_mode=&quot;condense_question&quot;, verbose=True)

    if prompt := st.chat_input(&quot;Your question&quot;): # Prompt for user input and save to chat history
        st.session_state.messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt})

    for message in st.session_state.messages: # Display the prior chat messages
        with st.chat_message(message[&quot;role&quot;]):
            st.write(message[&quot;content&quot;])

    # If last message is not from assistant, generate a new response
    if st.session_state.messages[-1][&quot;role&quot;] != &quot;assistant&quot;:
        with st.chat_message(&quot;assistant&quot;):
            with st.spinner(&quot;Thinking...&quot;):
                response = st.session_state.chat_engine.chat(prompt)
                st.write(response.response)
                message = {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: response.response}
                st.session_state.messages.append(message) # Add response to message history
</code></pre><figcaption>GPT Chatbot</figcaption></figure><p>Intuitively, it accepts the input from users, in this example it only accepts text and csv files, you can tweak the input types following the <a href="https://docs.streamlit.io/library/api-reference/widgets/st.file_uploader?ref=localhost">Streamlit guide</a>. </p><p>Then the input file are saved and used to create a vector store, which has been used for the GPT to refer to in the question-answering sessions.</p><h2 id="3-activate-the-chatbot">3 Activate the Chatbot</h2><p>In the terminal of your laptop, run command:</p><figure class="kg-card kg-code-card"><pre><code class="language-py">streamlit run main.py</code></pre><figcaption>Activate the App</figcaption></figure><p>The the app is up and you can upload your own files to the app, once that is done, the chat box will appear and you can ask questions regarding the data.</p><blockquote>The sample credit card transaction data can be downloaded at <a href="https://www.datacamp.com/workspace/datasets/dataset-python-credit-card-fraud?ref=localhost">datacamp</a>.</blockquote><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/bot_2.png" class="kg-image" alt="Build a Web-based GPT Chatbot with Custom Knowledge" loading="lazy"><figcaption>Chatbot UI</figcaption></figure><div class="kg-card kg-callout-card kg-callout-card-grey"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">Watch out the cost of the usage of OpenAI API, set a limit for the cost just to avoid unexpected intensive usage.</div></div><h2 id="reference">Reference</h2><p>LlamaIndex app demo on Streamlit Blog</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Build a chatbot with custom data sources, powered by LlamaIndex</div><div class="kg-bookmark-description">Augment any LLM with your own data in 43 lines of code!</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://blog.streamlit.io/content/images/size/w256h256/2021/03/favicon-transparent-1.png" alt="Build a Web-based GPT Chatbot with Custom Knowledge"><span class="kg-bookmark-author">Streamlit</span><span class="kg-bookmark-publisher">Caroline Frasca</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://blog.streamlit.io/content/images/2023/08/LinkedIn-post--Expand-me---11.png" alt="Build a Web-based GPT Chatbot with Custom Knowledge"></div></a></figure><p>Streamlit file uploader</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.streamlit.io/library/api-reference/widgets/st.file_uploader?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">st.file_uploader - Streamlit Docs</div><div class="kg-bookmark-description">st.file_uploader displays a file uploader widget.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://docs.streamlit.io/favicon.svg" alt="Build a Web-based GPT Chatbot with Custom Knowledge"><span class="kg-bookmark-author">Streamlit Docs</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.streamlit.io/sharing-image-facebook.jpg" alt="Build a Web-based GPT Chatbot with Custom Knowledge"></div></a></figure><p></p>]]></content:encoded></item><item><title><![CDATA[Build a macOS App Powered by Llama 2 in Three Steps]]></title><description><![CDATA[Swift-transformers help make it happen.]]></description><link>https://realvincentyuan.github.io/Spacecraft/build-a-macos-app-powered-by-llama-2-in-three-steps/</link><guid isPermaLink="false">668a1b22ac15d470add4a2dd</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[GenAI]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Thu, 07 Dec 2023 03:30:11 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1703693220150-422c569bb33e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyNHx8dnkxMjE4fGVufDB8fHx8MTcwNjQxNjI4OXww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Build a macOS App Powered by Llama 2 in Three Steps"><p>Generative AI has been generating a lot of buzz lately, and among the most discussed open-source large language models is Llama 2 made by Meta. Recently, the renowned Hugging Face team introduced a tool enabling the utilization of large language models within MacOS applications. This post aims to guide you through the process of integrating and leveraging Llama 2 effortlessly, empowering you to build your own applications seamlessly.</p><h2 id="1-prerequisite">1 Prerequisite</h2><p>In order to run the steps in this post, it is suggested that you have:</p><ul><li>A computer running macOS</li><li>Git, or GitHub client</li><li>Xcode, available for free in macOS App Store</li><li>Installed a few dependent Python packages</li></ul><p>Following the steps, you can build an macOS app that you can interact with like below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/swift-chat.png" class="kg-image" alt="Build a macOS App Powered by Llama 2 in Three Steps" loading="lazy"><figcaption>macOS App Powered by Llama 2</figcaption></figure><h2 id="2-swift-chat-code">2 Swift-Chat Code</h2><p>Clone the <a href="https://github.com/huggingface/swift-chat?ref=localhost">Swift-chat GitHub repo</a> by using below command:</p><pre><code class="language-bash">git clone https://github.com/huggingface/swift-chat</code></pre><p>If you are not familiar with Git/GitHub, kindly go to this tutorial:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://realvincentyuan.github.io/Spacecraft/how-to-use-github-without-writing-a-single-line-of-code/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">How to Use GitHub without Writing a Single Line of Code</div><div class="kg-bookmark-description">Healthy food for thoughts about this beautiful life!</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://realvincentyuan.github.io/Spacecraft/favicon.ico" alt="Build a macOS App Powered by Llama 2 in Three Steps"><span class="kg-bookmark-author">Spacecraft</span><span class="kg-bookmark-publisher">Vincent Yuan</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Build a macOS App Powered by Llama 2 in Three Steps"></div></a></figure><h2 id="3-xcode-build">3 Xcode Build</h2><p>Use Xcode to open the project file - <code>SwiftChat.xcodeproj</code> in that Git repo cloned in the last step:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/swift-chat_xcode.png" class="kg-image" alt="Build a macOS App Powered by Llama 2 in Three Steps" loading="lazy"><figcaption>Xcode Project</figcaption></figure><p>Click the play button on the top left to build the project and the app will show up.</p><h2 id="4-download-llama-2-coreml-model">4 Download Llama 2 CoreML Model</h2><p>A CoreML model is required to be loaded into the app, there are many ways to convert a PyTorch/TensorFlow models into a CoreML model as quoted below:</p><blockquote>1. Use the <a href="https://huggingface.co/spaces/coreml-projects/transformers-to-coreml?ref=localhost"><code>transformers-to-coreml</code></a> conversion Space:</blockquote><blockquote>This is an automated tool built on top of <code>exporters</code> (see below) that either works for your model, or doesn&apos;t. It requires no coding: enter the Hub model identifier, select the task you plan to use the model for, and click apply. If the conversion succeeds, you can push the converted Core ML weights to the Hub, and you are done!</blockquote><blockquote>2. Use <a href="https://github.com/huggingface/exporters?ref=localhost"><code>exporters</code></a>, a Python conversion package built on top of Apple&apos;s <code>coremltools</code> (see below).</blockquote><blockquote>This library gives you a lot more options to configure the conversion task. In addition, it lets you create your own <a href="https://github.com/huggingface/exporters?ref=localhost#overriding-default-choices-in-the-configuration-object">conversion configuration class</a>, which you may use for additional control or to work around conversion issues.</blockquote><blockquote>3. Use <a href="https://github.com/apple/coremltools?ref=localhost"><code>coremltools</code></a>, Apple&apos;s conversion package.</blockquote><blockquote>This is the lowest-level approach and therefore provides maximum control. It can still fail for some models (especially new ones), but you always have the option to dive inside the source code and try to figure out why.</blockquote><p>But per my experiment, the easiest way is to download the Llama 2 CoreML model from Hugging Face as below:</p><h3 id="41-install-huggingfacehub">4.1 Install huggingface_hub</h3><p>In the terminal, run below command to install huggingface_hub:</p><figure class="kg-card kg-code-card"><pre><code class="language-bash">pip install huggingface_hub</code></pre><figcaption>Install huggingface_hub</figcaption></figure><h3 id="42-download-the-llama-2-coreml-model">4.2 Download the Llama 2 CoreML Model</h3><p>Once the huggingface_hub is installed, you can use the <code>huggingface_cli</code> to download the model:</p><figure class="kg-card kg-code-card"><pre><code class="language-bash">huggingface-cli download --local-dir-use-symlinks False --local-dir ~/Download/Llama-2-7b-chat-coreml coreml-projects/Llama-2-7b-chat-coreml</code></pre><figcaption>Download Llama CoreML Model</figcaption></figure><p>You will be asked to provide the Hugging Face token if you do not have one, just click the link in the output and generate that token, then put it in the terminal, also, you can tweak the path to save the model by altering the value behind the <code>--local-dir</code> parameter.</p><h2 id="5-run-the-app">5 Run the App</h2><p>If the preceding steps have been successful, the app&apos;s user interface should now be visible. Proceed by clicking the button located in the left sidebar to load the model, enabling you to enjoy utilizing your personalized application!</p><p>This additional information serves to enhance the details not covered in the original post, simplifying the process. Much credit goes to the Hugging Face team for their remarkable efforts in this endeavor&#x2014;kudos to them!</p><h2 id="reference">Reference</h2><p>Post regarding the release of Swift Transformers:</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/blog/swift-coreml-llm?ref=localhost#model-and-hub-wrappers"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Releasing Swift Transformers: Run On-Device LLMs in Apple Devices</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Build a macOS App Powered by Llama 2 in Three Steps"></div></div><div class="kg-bookmark-thumbnail"><img src="https://huggingface.co/blog/assets/swift-coreml-llm/thumbnail.png" alt="Build a macOS App Powered by Llama 2 in Three Steps"></div></a></figure><p>Llama 2 CoreML model made by Hugging Face</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://huggingface.co/coreml-projects/Llama-2-7b-chat-coreml?ref=localhost"><div class="kg-bookmark-content"><div class="kg-bookmark-title">coreml-projects/Llama-2-7b-chat-coreml &#xB7; Hugging Face</div><div class="kg-bookmark-description">We&#x2019;re on a journey to advance and democratize artificial intelligence through open source and open science.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://huggingface.co/favicon.ico" alt="Build a macOS App Powered by Llama 2 in Three Steps"></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/models/coreml-projects/Llama-2-7b-chat-coreml.png" alt="Build a macOS App Powered by Llama 2 in Three Steps"></div></a></figure>]]></content:encoded></item></channel></rss>